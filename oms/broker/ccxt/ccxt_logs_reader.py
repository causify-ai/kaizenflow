"""
Import as:

import oms.broker.ccxt.ccxt_logs_reader as obcclore
"""
import logging
import os
from typing import Dict, List, Optional

import numpy as np
import pandas as pd
from tqdm.autonotebook import tqdm

import helpers.hdatetime as hdateti
import helpers.hdbg as hdbg
import helpers.hio as hio
import oms.broker.ccxt.abstract_ccxt_broker as obcaccbr

# TODO(Danya): CMTask4420.
# `extra_params` in `oms.Order` contains a dict, which is serialized in CSV
# as a string, which is converted back to dict using `eval`. `extra_params`
# contains time logging info in `datetime.datetime` format, and applying
# `eval` in `load_oms_child_order_df` requires this library to be imported.
import datetime  # pylint: disable=unused-import

_LOG = logging.getLogger(__name__)

# #############################################################################
# CcxtLogsReader
# #############################################################################

# TODO(gp): The format should be independent of v1 and v2. In the end Brokers
#  are different only in terms of
#  - parent vs child orders (e.g., a parent order can have a single child)
#  - timing of orders
class CcxtLogsReader:
    """
    Read all logs about trades and fills generated by a CCXT Broker.

    This includes:
    - Oms.Fills for all the CCXT trades
    - CCXT order responses for all children orders
    - Submitted child orders

    The expected structure of the logs folder is:
    ```
    {log_dir}/
        oms_parent_orders/
            - Initial input parent orders in the state before submission
        ccxt_child_order_responses/
            - Common to Broker_v1 and Broker_v2
        oms_child_orders/
            - Common to Broker_v1 and Broker_v2
        child_order_fills/
            ccxt_fills/
                - Information about closed orders from CCXT
                - Works only for v2
            oms_fills/
                - JSON representations of `oms.Fill` objects generated by the
                  Broker
                - Works only for v2
            ccxt_trades/
                - Output of CCXT `fetchMyTrades` method which contains the 'fees'
                  and 'realizedPNL' fields
                - Works only for v2
    ```
    """

    def __init__(
        self,
        root_dir: str,
    ):
        """
        :param root_dir: root location of broker logs,
          e.g. /shared_data/system_log_dir_20230315_30minutes/
        """
        #
        self._root_dir = root_dir
        self._get_log_subdirectories()

    def load_all_data(self) -> Dict[str, pd.DataFrame]:
        """
        Load all data.

        :return: dictionary storing the logged data
        """
        all_data = {
            "ccxt_order_responses": self.load_ccxt_order_response_df(),
            "oms_parent_orders": self.load_oms_parent_order_df(),
            "ccxt_trades": self.load_ccxt_trades_df(),
            "oms_child_orders": self.load_oms_child_order_df(),
            "oms_fills": self.load_oms_fills_df(),
            "ccxt_fills": self.load_ccxt_fills_df(),
        }
        return all_data

    def load_ccxt_order_response_df(
        self,
    ) -> pd.DataFrame:
        """
        Load CCXT order responses as a DataFrame.

        The order response is a CCXT order structure, as described in
        https://docs.ccxt.com/#/?id=order-structure.

        E.g., a timeseries from return DataFrame looks like:
        ```
        info                    {'orderId': '7954906695', 'symbol': 'APEUSDT',...
        order                   7954906695
        client_order_id             x-xcKtGhcub89989e55d47273a3610a9
        timestamp                1678898138582
        datetime                 2023-03-15 16:35:38.582000+00:00
        last_trade_timestamp          None
        symbol                  APE/USDT
        order_type                limit
        time_in_force              GTC
        post_only                False
        reduce_only               False
        side                    buy
        order_price               4.12
        stop_price                NaN
        order_amount              10.0
        cost                    0.0
        average                 NaN
        filled                   0.0
        remaining                10.0
        status                  open
        fee                    NaN
        trades                  []
        fees                   []
        order_update_timestamp       1678898138582
        order_update_datetime        1970-01-01 00:27:58.898138582+00:00
        ```
        """
        # Get the files.
        files = self._get_files(self._ccxt_order_responses_dir)
        # Read all the files.
        ccxt_order_responses = []
        for path in tqdm(
            files, desc=f"Loading files from '{self._ccxt_order_responses_dir}'"
        ):
            data = hio.from_json(path, use_types=True)
            ccxt_order_responses.append(data)
        # Assemble the output df.
        ccxt_order_responses = self._convert_ccxt_order_structures_to_dataframe(
            ccxt_order_responses
        )
        return ccxt_order_responses

    def load_oms_parent_order_df(self) -> pd.DataFrame:
        """
        Load and normalize "parent" orders.
        """
        # Get the files.
        # Specify the file extension as JSON, as OMS parent order folder
        # contains multiple copies of the same parent orders with extra
        # params updated at each wave of child orders.
        # Latest OMS parent orders have the file name pattern:
        # `oms_parent_orders_{bar_timestamp}.json`.
        # Outdated OMS parent order for previous waves:
        # `oms_parent_orders_{bar_timestamp}.json.{wall_clock_time}`.
        # `wall_clock_time` indicates the point up to which these logs were relevant.
        files = self._get_files(
            self._oms_parent_orders_dir, file_extension="json"
        )
        # Read all the files.
        parent_orders = []
        # Load individual orders as pd.Series.
        for path in tqdm(
            files, desc=f"Loading files from '{self._oms_parent_orders_dir}'"
        ):
            # Load parent order files from JSON format.
            data = hio.from_json(path, use_types=True)
            parent_orders.extend(data)
        # Assemble the output df.
        oms_parent_order_df = self._convert_oms_parent_orders_to_dataframe(
            parent_orders
        )
        return oms_parent_order_df

    def load_oms_child_order_df(
        self, unpack_extra_params: bool = False
    ) -> pd.DataFrame:
        """
        Load and normalize "child" orders.

        :param unpack_extra_params: if True, unpack `extra_params` field into output DataFrame columns

        Example of returned data:
        ```
                creation_timestamp              asset_id    type_  \
        order_id
        20       2023-03-15 16:35:37.825835+00:00  6051632686  limit
        21       2023-03-15 16:35:38.718960+00:00  8717633868  limit

                start_timestamp               end_timestamp  \
        order_id
        20       2023-03-15 16:35:37.825835+00:00 2023-03-15 16:36:37.825835+00:00
        21       2023-03-15 16:35:38.718960+00:00 2023-03-15 16:36:38.718960+00:00

                curr_num_shares  diff_num_shares  tz            passivity_factor    \
        order_id
        20       0.0          10.0        America/New_York   0.55
        21       0.0          -1.0        America/New_York    0.55

                latest_bid_price  latest_ask_price  bid_price_mean  ask_price_mean  \
        order_id
        20       4.120             4.121    4.125947    4.126974
        21       15.804            15.805   15.818162   15.819432

                used_bid_price    used_ask_price  limit_price      ccxt_id  \
        order_id
        20       latest_bid_price  latest_ask_price    4.12045   7954906695
        21       latest_bid_price  latest_ask_price    15.80455  14412582631
        ```
        """
        # Get the files.
        files = self._get_files(self._oms_child_orders_dir)
        # Read all the files.
        child_orders = []
        # Load individual orders as pd.Series.
        for path in tqdm(
            files, desc=f"Loading files from '{self._oms_child_orders_dir}'"
        ):
            # Load individual orders in pd.Series format.
            data = hio.from_json(path, use_types=True)
            child_orders.append(data)
        # Assemble the output df.
        oms_child_orders_df = self._convert_oms_child_orders_to_dataframe(
            child_orders,
            unpack_extra_params=unpack_extra_params,
        )
        return oms_child_orders_df

    def load_ccxt_trades_df(self) -> pd.DataFrame:
        """
        Load trades as DataFrame.

        Example of one entity of input JSON data:
        ```
        {
        "info": {
            "symbol": "APEUSDT",
            "id": "356819245",
            "orderId": "8077704766",
            "side": "SELL",
            "price": "4.0400",
            "qty": "6",
            "realizedPnl": 0.0,
            "marginAsset": "USDT",
            "quoteQty": "24.2400",
            "commission": "0.00969600",
            "commissionAsset": "USDT",
            "time": "1679560540879",
            "positionSide": "BOTH",
            "buyer": False,
            "maker": False
        },
            "timestamp": 1679560540879,
            "datetime": "Timestamp('2023-03-23 08:35:40.879000+0000', tz='UTC')",
            "symbol": "APE/USDT",
            "asset_id": 6051632686,
            "id": 356819245,
            "order": 8077704766,
            "type": None,
            "side": "sell",
            "takerOrMaker": "taker",
            "price": 4.04,
            "amount": 6.0,
            "cost": 24.24,
            "fee": {
                "cost": 0.009696,
                "currency": "USDT"
            },
            "fees": [
                {
                    "currency": "USDT",
                    "cost": 0.009696
                }
            ]
        }
        ```

        Example of returned data:
        ```
                                timestamp    symbol         id       order  side  \
        0 2022-09-29 16:46:39.509000+00:00  APE/USDT  282773274  5772340563  sell
        1 2022-09-29 16:51:58.567000+00:00  APE/USDT  282775654  5772441841   buy
        2 2022-09-29 16:57:00.267000+00:00  APE/USDT  282779084  5772536135   buy
        3 2022-09-29 17:02:00.329000+00:00  APE/USDT  282780259  5772618089  sell
        4 2022-09-29 17:07:03.097000+00:00  APE/USDT  282781536  5772689853   buy

        takerOrMaker  price  amount    cost      fees fees_currency realized_pnl
        0        taker  5.427     5.0  27.135  0.010854          USDT            0
        1        taker  5.398     6.0  32.388  0.012955          USDT   0.14500000
        2        taker  5.407     3.0  16.221  0.006488          USDT            0
        3        taker  5.395     9.0  48.555  0.019422          USDT  -0.03900000
        4        taker  5.381     8.0  43.048  0.017219          USDT   0.07000000
        ```
        """
        # Get the files.
        files = self._get_files(self._ccxt_trades_dir)
        # Read all the files.
        ccxt_child_order_trades = []
        for path in tqdm(
            files, desc=f"Loading files from '{self._ccxt_trades_dir}'"
        ):
            data = hio.from_json(path, use_types=True)
            ccxt_child_order_trades.extend(data)
        # Convert fills to DataFrame.
        ccxt_child_order_trades = self._convert_ccxt_trades_json_to_dataframe(
            ccxt_child_order_trades
        )
        # Remove full duplicates for fills.
        # Note: generally fills are loaded in bulk via CCXT `fetchMyTrades()`
        # method, which allows only for queries based on time range and full
        # symbol. In some cases, there is an overlap between queries, which leads
        # to full duplicates appearing in the resulting DataFrame.
        # Duplicates are determined via timestamp, `id` of the trade and `order` id.
        ccxt_child_order_trades_deduped = ccxt_child_order_trades.drop_duplicates(
            subset=["timestamp", "id", "order"], keep="last"
        )
        # TODO(pp): Use hdbg.to_perc to get a better output.
        _LOG.debug(
            "%s duplicates were removed from original data.",
            ccxt_child_order_trades.shape[0]
            - ccxt_child_order_trades_deduped.shape[0],
        )
        return ccxt_child_order_trades_deduped

    def load_oms_fills_df(self) -> pd.DataFrame:
        """
        Load the oms fills representation from JSON.

        Example of input data:
        ```
        {
            "asset_id": 5115052901,
            "fill_id": 6,
            "timestamp": "2023-05-23T11:58:50.201000+00:00",
            "num_shares": 93.0,
            "price": 69.5733
        }
        ```

        Example of returned data:
        ```
           asset_id         fill_id  timestamp                      num_shares    price
        0  8717633868        2  2023-05-23T11:58:49.172000+00:00       1.000  14.7540
        1  1467591036        4  2023-05-23T11:58:49.687000+00:00       0.001  27.3304
        2  5115052901        6  2023-05-23T11:58:50.201000+00:00      93.000  69.5733
        3  3401245610        7  2023-05-23T11:58:50.456000+00:00       3.000   6.5460
        ```

        Works only for version v2.
        """
        files = self._get_files(self._oms_fills_dir)
        oms_child_order_fills = []
        for path in tqdm(
            files, desc=f"Loading files from '{self._oms_fills_dir}'"
        ):
            data = hio.from_json(path, use_types=True)
            oms_child_order_fills.extend(data)
        oms_child_order_fills = pd.DataFrame(oms_child_order_fills)
        return oms_child_order_fills

    def load_ccxt_fills_df(self) -> pd.DataFrame:
        """
        Load the CCXT filled order representations from JSON.

        These representations correspond to closed orders.

        Example of one entity of input JSON data:
        ```
        {
        "info": {
            "orderId": "2187830797",
            "symbol": "CTKUSDT",
            "status": "FILLED",
            "clientOrderId": "x-xcKtGhcuda5dde8563a5c1568a5893",
            "price": "0.74810",
            "avgPrice": "0.74810",
            "origQty": "93",
            "executedQty": "93",
            "cumQuote": "69.57330",
            "timeInForce": "GTC",
            "type": "LIMIT",
            "reduceOnly": False,
            "closePosition": False,
            "side": "BUY",
            "positionSide": "BOTH",
            "stopPrice": "0",
            "workingType": "CONTRACT_PRICE",
            "priceProtect": False,
            "origType": "LIMIT",
            "time": "1684843130201",
            "updateTime": 1684843130201
        },
        "id": 2187830797,
        "clientOrderId": "x-xcKtGhcuda5dde8563a5c1568a5893",
        "timestamp": 1684843130201,
        "datetime": "Timestamp('2023-05-23 11:58:50.201000+0000', tz='UTC')",
        "lastTradeTimestamp": None,
        "symbol": "CTK/USDT",
        "type": "limit",
        "timeInForce": "GTC",
        "postOnly": False,
        "reduceOnly": False,
        "side": "buy",
        "price": 0.7481,
        "stopPrice": "nan",
        "amount": 93.0,
        "cost": 69.5733,
        "average": 0.7481,
        "filled": 93.0,
        "remaining": 0.0,
        "status": "closed",
        "fee": "nan",
        "trades": [],
        "fees": []
        }
        ```

        E.g., a timeseries from return DataFrame looks like:
        ```
        info                      {'orderId': '14901643572', 'symbol': 'AVAXUSDT...
        order                      14901643572
        client_order_id                x-xcKtGhcu8261da0e4a2533b528e0e2
        timestamp                   1684843129172
        datetime                    2023-05-23 11:58:49.172000+00:00
        last_trade_timestamp             None
        symbol                     AVAX/USDT
        order_type                   limit
        time_in_force                 GTC
        post_only                   False
        reduce_only                  False
        side                       buy
        order_price                  14.761
        stop_price                   NaN
        order_amount                 1.0
        cost                      14.754
        average                    14.754
        filled                      1.0
        remaining                   0.0
        status                     closed
        fee                       NaN
        trades                     []
        fees                      []
        order_update_timestamp          1684843129172
        order_update_datetime           1970-01-01 00:28:04.843129172+00:00
        ```

        Works only for version v2.
        """
        files = self._get_files(self._ccxt_fills_dir)
        ccxt_fills = []
        for path in tqdm(
            files, desc=f"Loading `{self._ccxt_fills_dir}` files..."
        ):
            data = hio.from_json(path, use_types=True)
            ccxt_fills.extend(data)
        ccxt_fills = self._convert_ccxt_order_structures_to_dataframe(ccxt_fills)
        return ccxt_fills

    @staticmethod
    def _get_files(
        log_dir: str, *, file_extension: Optional[str] = None
    ) -> List[str]:
        """
        Get a list of files from the directory.

        :param file_extension: added to the file search pattern, e.g. "json".
         Can be used with or without the initial "."
        """
        pattern = "*"
        if file_extension:
            pattern += file_extension
        only_files = True
        use_relative_paths = False
        files: List[str] = hio.listdir(
            log_dir, pattern, only_files, use_relative_paths
        )
        files.sort()
        return files

    @staticmethod
    def _convert_ccxt_order_structures_to_dataframe(
        ccxt_order_structures: List[obcaccbr.CcxtData],
    ) -> pd.DataFrame:
        """
        Convert a list of CCXT order structures to a DataFrame.

        `child_order_response` and `ccxt_fill` are exactly the same data
        structures (see http://docs.ccxt.com/#/?id=order-structure) that
        we encode as `obcaccbr.CcxtData` (`Dict[str, Any]` under the
        hood). Thus, we refer to the common data structure as
        `ccxt_order_structure` and use this function for both data
        structures.
        """
        ccxt_order_structures_series_list = []
        for ccxt_order_structure in ccxt_order_structures:
            # Skip the response JSON if it is empty.
            if not ccxt_order_structure:
                continue
            srs = pd.Series(
                ccxt_order_structure.values(), ccxt_order_structure.keys()
            )
            # Get order update Unix timestamp from the exchange.
            info_timestamp = ccxt_order_structure["info"]["updateTime"]
            srs["info_timestamp"] = info_timestamp
            # Convert to datetime.
            srs["info_datetime"] = pd.to_datetime(
                info_timestamp, unit="ms", utc=True
            )
            ccxt_order_structures_series_list.append(srs)
        ccxt_order_df = pd.concat(ccxt_order_structures_series_list, axis=1).T
        # Transform timestamp columns to UTC.
        ccxt_order_df = ccxt_order_df.applymap(
            lambda x: x.tz_convert("UTC") if isinstance(x, pd.Timestamp) else x
        )
        #  Check the timestamp logs in `CcxtBroker_v2` and update the conversion accordingly.
        # Rename columns.
        ccxt_order_df = ccxt_order_df.rename(
            columns={
                "id": "order",
                "clientOrderId": "client_order_id",
                "lastTradeTimestamp": "last_trade_timestamp",
                "type": "order_type",
                "timeInForce": "time_in_force",
                "postOnly": "post_only",
                "reduceOnly": "reduce_only",
                "price": "order_price",
                "stopPrice": "stop_price",
                "amount": "order_amount",
                "info_timestamp": "order_update_timestamp",
                "info_datetime": "order_update_datetime",
            }
        )
        return ccxt_order_df

    @staticmethod
    def _normalize_fills_dataframe(fills_df: pd.DataFrame) -> pd.DataFrame:
        """
        Validate a fills DataFrame and normalize for chaining
        `obccagfu._aggregate_fills()`.

        Ensure `df` is a DataFrame with certain columns and restricted values.

        :param df: a fills DataFrame as returned by
            `convert_fills_json_to_dataframe()`
        """
        # Sanity-check the DataFrame.
        hdbg.dassert_isinstance(fills_df, pd.DataFrame)
        required_cols = [
            "timestamp",
            "datetime",
            "side",
            "takerOrMaker",
            "price",
            "amount",
            "cost",
            "transaction_cost",
        ]
        hdbg.dassert_is_subset(required_cols, fills_df.columns)
        # Ensure categoricals lie in expected sets.
        hdbg.dassert_is_subset(fills_df["side"].unique(), ["buy", "sell"])
        hdbg.dassert_is_subset(
            fills_df["takerOrMaker"].unique(), ["taker", "maker", np.nan]
        )
        # Check self-consistency of prices/costs/amounts.
        hdbg.dassert_lte(
            ((fills_df["cost"] / fills_df["amount"]) - fills_df["price"]).sum(),
            1e-6,
        )
        #
        fills_df = fills_df.copy()
        fills_df["datetime"] = pd.to_datetime(fills_df["datetime"])
        # Assign additional datetime columns.
        fills_df["first_timestamp"] = fills_df["timestamp"]
        fills_df["last_timestamp"] = fills_df["timestamp"]
        fills_df["first_datetime"] = fills_df["datetime"]
        fills_df["last_datetime"] = fills_df["datetime"]
        # Accumulate buy/sell counts.
        fills_df["buy_count"] = (fills_df["side"] == "buy").astype(int)
        fills_df["sell_count"] = (fills_df["side"] == "sell").astype(int)
        # Accumulate taker/maker counts.
        fills_df["taker_count"] = (fills_df["takerOrMaker"] == "taker").astype(
            int
        )
        fills_df["maker_count"] = (fills_df["takerOrMaker"] == "maker").astype(
            int
        )
        # Process fills data for volume.
        fills_df["buy_volume"] = np.where(
            fills_df["side"] == "buy", fills_df["amount"], 0
        )
        fills_df["sell_volume"] = np.where(
            fills_df["side"] == "sell", fills_df["amount"], 0
        )
        fills_df["taker_volume"] = np.where(
            fills_df["takerOrMaker"] == "taker", fills_df["amount"], 0
        )
        fills_df["maker_volume"] = np.where(
            fills_df["takerOrMaker"] == "maker", fills_df["amount"], 0
        )
        # Process fills data for notional.
        fills_df["buy_notional"] = np.where(
            fills_df["side"] == "buy", fills_df["cost"], 0
        )
        fills_df["sell_notional"] = np.where(
            fills_df["side"] == "sell", fills_df["cost"], 0
        )
        fills_df["taker_notional"] = np.where(
            fills_df["takerOrMaker"] == "taker", fills_df["cost"], 0
        )
        fills_df["maker_notional"] = np.where(
            fills_df["takerOrMaker"] == "maker", fills_df["cost"], 0
        )
        return fills_df

    @staticmethod
    def _convert_oms_fills_to_dataframe(
        oms_fills: List[obcaccbr.CcxtData],
    ) -> pd.DataFrame:
        """
        Convert a list of OMS fill dicts into a DataFrame.
        """
        oms_fills_df = pd.DataFrame(oms_fills)
        #
        expected_columns = [
            "asset_id",
            "fill_id",
            "timestamp",
            "num_shares",
            "price",
        ]
        hdbg.dassert_set_eq(oms_fills_df.columns, expected_columns)
        return oms_fills_df

    def _convert_oms_parent_orders_to_dataframe(
        self, oms_parent_orders: List[obcaccbr.CcxtData]
    ) -> pd.DataFrame:
        """
        Convert a list of OMS parent orders into a single DataFrame and
        normalize.

        Example of input OMS parent orders:
        [OrderedDict([('order_id', 0),
        ('creation_timestamp',
        Timestamp('2023-06-21 10:15:49.589872-0400',
        tz='America/New_York')),                         ('asset_id',
        3065029174),                         ('type_', 'price@twap'),
        ('start_timestamp',
        Timestamp('2023-06-21 10:15:49.589872-0400',
        tz='America/New_York')),
        ('end_timestamp',                         Timestamp('2023-06-21
        10:20:49.589872-0400', tz='America/New_York')),
        ('curr_num_shares', 0.0),
        ('diff_num_shares', -900.0),                         ('tz',
        <DstTzInfo 'America/New_York' EST-1 day, 19:00:00 STD>),
        ('extra_params', {})]),             OrderedDict([('order_id',
        1),                         ('creation_timestamp',
        Timestamp('2023-06-21 10:15:49.590399-0400',
        tz='America/New_York')),                         ('asset_id',
        6051632686),                         ('type_', 'limit'),
        ('start_timestamp',
        Timestamp('2023-06-21 10:15:49.590399-0400',
        tz='America/New_York')),
        ('end_timestamp',                         Timestamp('2023-06-21
        10:20:49.590399-0400', tz='America/New_York')),
        ('curr_num_shares', 0.0),
        ('diff_num_shares', 33.0),                         ('tz',
        <DstTzInfo 'America/New_York' EST-1 day, 19:00:00 STD>),
        ('extra_params', {})])]         Example of output:         ```
        creation_timestamp    asset_id       type_
        start_timestamp                    end_timestamp
        curr_num_shares  diff_num_shares               tz
        extra_params order_id 0        2023-06-22 08:44:21.852271+00:00
        3065029174  price@twap 2023-06-22 08:44:21.852271+00:00
        2023-06-22 08:49:21.852271+00:00              0.0
        -900.0  America/New_York           {} 1        2023-06-22
        08:44:21.852754+00:00  6051632686       limit 2023-06-22
        08:44:21.852754+00:00 2023-06-22 08:49:21.852754+00:00
        0.0             33.0  America/New_York           {}         ```
        """
        # Combine into a single DataFrame.
        oms_parent_orders_df = pd.DataFrame(oms_parent_orders)
        oms_parent_orders_df = oms_parent_orders_df.set_index("order_id")
        # Transform timestamp columns to UTC.
        oms_parent_orders_df = oms_parent_orders_df.applymap(
            lambda x: x.tz_convert("UTC") if isinstance(x, pd.Timestamp) else x
        )
        return oms_parent_orders_df

    def _convert_oms_child_orders_to_dataframe(
        self,
        oms_child_orders: List[obcaccbr.CcxtData],
        *,
        unpack_extra_params: bool = False,
    ) -> pd.DataFrame:
        """
        Convert list of OMS child order Series into a DataFrame and normalize.

        Example of input OMS child order:
        ```
        {
            "order_id": 20,
            "creation_timestamp": "Timestamp('2023-03-15 12:35:37.825835-0400', tz='pytz.FixedOffset(-240)')",
            "asset_id": 6051632686,
            "type_": "limit",
            "start_timestamp": "Timestamp('2023-03-15 12:35:37.825835-0400', tz='pytz.FixedOffset(-240)')",
            "end_timestamp": "Timestamp('2023-03-15 12:36:37.825835-0400', tz='pytz.FixedOffset(-240)')",
            "curr_num_shares": 0.0,
            "diff_num_shares": 10.0,
            "tz": "America/New_York",
            "passivity_factor": 0.55,
            "latest_bid_price": 4.12,
            "latest_ask_price": 4.121,
            "bid_price_mean": 4.125947368421053,
            "ask_price_mean": 4.126973684210526,
            "used_bid_price": "latest_bid_price",
            "used_ask_price": "latest_ask_price",
            "limit_price": 4.12045,
            "ccxt_id": 7954906695
        }
        ```

        E.g., a timeseries from return DataFrame:
        ```
        order_id                 20
        creation_timestamp          2023-03-15 12:35:37.825835-04:00
        asset_id                 6051632686
        type_                   limit
        start_timestamp            2023-03-15 12:35:37.825835-04:00
        end_timestamp             2023-03-15 12:36:37.825835-04:00
        curr_num_shares            0.0
        diff_num_shares            10.0
        tz                     America/New_York
        passivity_factor            0.55                                                                                                                 latest_bid_price                                                   4.12
        latest_ask_price            4.121
        bid_price_mean             4.125947368421053
        ask_price_mean             4.126973684210526                                                                                                                 used_bid_price                                         latest_bid_price
        used_ask_price             latest_ask_price                                                                                                                 limit_price                                                     4.12045
        ccxt_id                  7954906695
        extra_params              {'order_generated_timestamp': datetime.datetim...
        ```
        """
        # Convert to DataFrame.
        oms_child_orders_series_list = []
        for oms_child_order_srs in oms_child_orders:
            order_id = oms_child_order_srs["order_id"]
            # Name each series according to internal order_id.
            oms_child_order_srs["name"] = order_id
            oms_child_orders_series_list.append(oms_child_order_srs)
        oms_child_orders_df = pd.DataFrame(oms_child_orders_series_list)
        oms_child_orders_df = oms_child_orders_df.set_index("order_id")
        # Transform timestamp columns to UTC.
        oms_child_orders_df = oms_child_orders_df.applymap(
            lambda x: x.tz_convert("UTC") if isinstance(x, pd.Timestamp) else x
        )
        # Unpack ccxt_id from the list format.
        # E.g. [12028516372] -> 12028516372.
        hdbg.dassert_in("ccxt_id", oms_child_orders_df.columns)
        # Make sure that all CCXT ID lists have length of 1.
        hdbg.dassert_eq_all(set(oms_child_orders_df["ccxt_id"].str.len()), {1})
        oms_child_orders_df["ccxt_id"] = oms_child_orders_df["ccxt_id"].apply(
            lambda x: x[0]
        )
        if unpack_extra_params:
            # Unpack 'extra params' dictionary into a DataFrame.
            extra_params_df = oms_child_orders_df["extra_params"].apply(pd.Series)
            # Add extra_params columns to the child orders DataFrame.
            oms_child_orders_df = pd.concat(
                [oms_child_orders_df, extra_params_df], axis=1
            )
            # Remove the extra_params column to avoid data duplication.
            oms_child_orders_df = oms_child_orders_df.drop(
                ["extra_params"], axis=1
            )
        return oms_child_orders_df

    def _convert_ccxt_trades_json_to_dataframe(
        self, trades_json: List[obcaccbr.CcxtData]
    ) -> pd.DataFrame:
        """
        Convert JSON-format trades into a DataFrame.

        - Unpack nested values;
        - Convert unix epoch to pd.Timestamp;
        - Remove duplicated information;
        """
        hdbg.dassert_lte(1, len(trades_json))
        trades = pd.DataFrame(trades_json)
        hdbg.dassert_in("asset_id", trades.columns)
        # Extract nested values.
        # Note: `transaction_cost` is extracted from the `fee`
        #  value for the base/quote currency.
        #  See https://docs.ccxt.com/#/?id=trade-structure.
        #
        trades["transaction_cost"] = [fee["cost"] for fee in trades["fee"]]
        trades["fees_currency"] = [fee["currency"] for fee in trades["fee"]]
        trades["realized_pnl"] = [info["realizedPnl"] for info in trades["info"]]
        # Force conversion of PnL to float.
        # PnL is extracted from `info` field, which stores all values as strings.
        trades["realized_pnl"] = trades["realized_pnl"].astype(float)
        # Replace unix epoch with a timestamp.
        trades["timestamp"] = trades["timestamp"].apply(
            hdateti.convert_unix_epoch_to_timestamp
        )
        # Set columns.
        columns = [
            "timestamp",
            "datetime",
            "symbol",
            "asset_id",
            "id",
            "order",
            "side",
            "takerOrMaker",
            "price",
            "amount",
            "cost",
            "transaction_cost",
            "fees_currency",
            "realized_pnl",
        ]
        trades = trades[columns]
        # Normalize data types.
        trades = self._normalize_fills_dataframe(trades)
        # Set timestamp index.
        trades = trades.set_index("timestamp", drop=False)
        return trades

    def _get_log_subdirectories(self) -> None:
        """
        Generate and store subdirectories with Broker logs.

        The directory is expected to follow the same structure, with
        fills and orders stored in '{root_dir}/'
        """
        hdbg.dassert_path_exists(self._root_dir)
        child_order_fills_dir = os.path.join(self._root_dir, "child_order_fills")
        hdbg.dassert_path_exists(child_order_fills_dir)
        # Verify that the fills dir conforms to expected structure.
        # If there are no subdirectories, the reader expects to find child order fill logs.
        # If there are subdirectories, the reader expect them to conform to the structure outlined in the constructor.
        child_order_fills_dir_contents = os.scandir(child_order_fills_dir)
        has_subdirectories = any(
            [path.is_dir() for path in child_order_fills_dir_contents]
        )
        if has_subdirectories:
            # Get a subdirectory for CCXT fill representations.
            # E.g. 'system_log_dir_20230315_30minutes/child_order_fills/ccxt_fills'.
            oms_fills_dir = os.path.join(child_order_fills_dir, "ccxt_fills")
            hdbg.dassert_path_exists(oms_fills_dir)
            self._ccxt_fills_dir = oms_fills_dir
            # Get a subdirectory for CCXT trades.
            # E.g. 'system_log_dir_20230315_30minutes/child_order_fills/ccxt_trades'.
            ccxt_child_order_trades_dir = os.path.join(
                child_order_fills_dir, "ccxt_trades"
            )
            hdbg.dassert_path_exists(ccxt_child_order_trades_dir)
            self._ccxt_trades_dir = ccxt_child_order_trades_dir
            # Get a subdirectory for OMS fills.
            # E.g. 'system_log_dir_20230315_30minutes/child_order_fills/oms_fills'.
            oms_fills_dir = os.path.join(child_order_fills_dir, "oms_fills")
            hdbg.dassert_path_exists(oms_fills_dir)
            self._oms_fills_dir = oms_fills_dir
        else:
            # Get subdirectory for CCXT representations child order fills.
            # E.g. 'system_log_dir_20230315_30minutes/child_order_fills'.
            self._ccxt_trades_dir = child_order_fills_dir
        # Get subdirectory for CCXT order responses.
        # E.g. 'system_log_dir_20230315_30minutes/ccxt_child_order_responses'.
        ccxt_order_responses_dir = os.path.join(
            self._root_dir, "ccxt_child_order_responses"
        )
        hdbg.dassert_path_exists(ccxt_order_responses_dir)
        self._ccxt_order_responses_dir = ccxt_order_responses_dir
        # Get subdirectory for submitted child orders.
        # E.g. 'system_log_dir_20230315_30minutes/oms_child_orders'.
        oms_child_orders_dir = os.path.join(self._root_dir, "oms_child_orders")
        hdbg.dassert_path_exists(oms_child_orders_dir)
        self._oms_child_orders_dir = oms_child_orders_dir
        # Get subdirectory for parent orders.
        # E.g. 'system_log_dir_20230315_30minutes/oms_parent_orders/'.
        oms_parent_orders_dir = os.path.join(self._root_dir, "oms_parent_orders")
        hdbg.dassert_path_exists(oms_parent_orders_dir)
        self._oms_parent_orders_dir = oms_parent_orders_dir

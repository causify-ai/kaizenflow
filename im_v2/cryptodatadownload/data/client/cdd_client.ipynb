{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e392c55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import as:\n",
    "\n",
    "import im.cryptodatadownload.data.load.loader as imcdalolo\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416fb88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0284d66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba89cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import core.pandas_helpers as cpanh\n",
    "import helpers.datetime_ as hdateti\n",
    "import helpers.dbg as hdbg\n",
    "import helpers.hpandas as hpandas\n",
    "import helpers.s3 as hs3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fb9a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "_LOG = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fc9fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latest historical data snapsot.\n",
    "_LATEST_DATA_SNAPSHOT = \"20210924\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8a71dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CddLoader:\n",
    "    def __init__(\n",
    "        self,\n",
    "        root_dir: str,\n",
    "        aws_profile: Optional[str] = None,\n",
    "        remove_dups: bool = True,\n",
    "        resample_to_1_min: bool = True,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Load CDD data.\n",
    "\n",
    "        :param: root_dir: either a local root path (e.g., \"/app/im\") or\n",
    "            an S3 root path (e.g., \"s3://alphamatic-data/data) to CDD data\n",
    "        :param: aws_profile: AWS profile name (e.g., \"am\")\n",
    "        :param remove_dups: whether to remove full duplicates or not\n",
    "        :param resample_to_1_min: whether to resample to 1 min or not\n",
    "        \"\"\"\n",
    "        self._root_dir = root_dir\n",
    "        self._aws_profile = aws_profile\n",
    "        self._remove_dups = remove_dups\n",
    "        self._resample_to_1_min = resample_to_1_min\n",
    "        self._s3fs = hs3.get_s3fs(self._aws_profile)\n",
    "        # Specify supported data types to load.\n",
    "        self._data_types = [\"ohlcv\"]\n",
    "\n",
    "    def read_data_from_filesystem(\n",
    "        self,\n",
    "        exchange_id: str,\n",
    "        currency_pair: str,\n",
    "        data_type: str,\n",
    "        data_snapshot: Optional[str] = None,\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Load data from S3 and process it for use downstream.\n",
    "\n",
    "        :param exchange_id: CDD exchange id, e.g. \"binance\"\n",
    "        :param currency_pair: currency pair, e.g. \"BTC_USDT\"\n",
    "        :param data_type: OHLCV or trade, bid/ask data\n",
    "        :param data_snapshot: snapshot of datetime when data was loaded, e.g. \"20210924\"\n",
    "        :return: processed CDD data\n",
    "        \"\"\"\n",
    "        data_snapshot = data_snapshot or _LATEST_DATA_SNAPSHOT\n",
    "        # Verify that requested data type is valid.\n",
    "        hdbg.dassert_in(\n",
    "            data_type.lower(),\n",
    "            self._data_types,\n",
    "            msg=\"Incorrect data type: '%s'. Acceptable types: '%s'\"\n",
    "            % (data_type.lower(), self._data_types),\n",
    "        )\n",
    "        # Get absolute file path for a CDD file.\n",
    "        file_path = self._get_file_path(data_snapshot, exchange_id, currency_pair)\n",
    "        # Initialize kwargs dict for further CDD data reading.\n",
    "        # Add \"skiprows\" to kwargs in order to skip a row with the file name.\n",
    "        read_csv_kwargs = {\"skiprows\": 1}\n",
    "        #\n",
    "        if hs3.is_s3_path(file_path):\n",
    "            # Add s3fs argument to kwargs.\n",
    "            read_csv_kwargs[\"s3fs\"] = self._s3fs\n",
    "        # Read raw CDD data.\n",
    "        _LOG.info(\n",
    "            \"Reading CDD data for exchange id='%s', currencies='%s', from file='%s'...\",\n",
    "            exchange_id,\n",
    "            currency_pair,\n",
    "            file_path,\n",
    "        )\n",
    "        data = cpanh.read_csv(file_path, **read_csv_kwargs)\n",
    "        # Apply transformation to raw data.\n",
    "        _LOG.info(\n",
    "            \"Processing CDD data for exchange id='%s', currencies='%s'...\",\n",
    "            exchange_id,\n",
    "            currency_pair,\n",
    "        )\n",
    "        transformed_data = self._transform(\n",
    "            data, exchange_id, currency_pair, data_type\n",
    "        )\n",
    "        return transformed_data\n",
    "\n",
    "    # TODO(Grisha): factor out common code from `CddLoader._get_file_path` and\n",
    "    # `CcxtLoader._get_file_path`.\n",
    "    def _get_file_path(\n",
    "        self,\n",
    "        data_snapshot: str,\n",
    "        exchange_id: str,\n",
    "        currency_pair: str,\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Get the absolute path to a file with CDD data.\n",
    "\n",
    "        The file path is constructed in the following way:\n",
    "        `<root_dir>/cryptodatadownload/<snapshot>/<exchange_id>/<currency_pair>.csv.gz`.\n",
    "\n",
    "        :param data_snapshot: snapshot of datetime when data was loaded,\n",
    "            e.g. \"20210924\"\n",
    "        :param exchange_id: CDD exchange id, e.g. \"binance\"\n",
    "        :param currency_pair: currency pair `<currency1>_<currency2>`,\n",
    "            e.g. \"BTC_USDT\"\n",
    "        :return: absolute path to a file with CDD data\n",
    "        \"\"\"\n",
    "        # Get absolute file path.\n",
    "        file_name = currency_pair + \".csv.gz\"\n",
    "        file_path = os.path.join(\n",
    "            self._root_dir,\n",
    "            \"cryptodatadownload\",\n",
    "            data_snapshot,\n",
    "            exchange_id,\n",
    "            file_name,\n",
    "        )\n",
    "        # TODO(Dan): Remove asserts below after CMTask108 is resolved.\n",
    "        # Verify that the file exists.\n",
    "        if hs3.is_s3_path(file_path):\n",
    "            hs3.dassert_s3_exists(file_path, self._s3fs)\n",
    "        else:\n",
    "            hdbg.dassert_file_exists(file_path)\n",
    "        return file_path\n",
    "\n",
    "    # TODO(*): Consider making `exchange_id` a class member.\n",
    "    # TODO(*): Replace currencies separator \"/\" to \"_\".\n",
    "    def _transform(\n",
    "        self,\n",
    "        data: pd.DataFrame,\n",
    "        exchange_id: str,\n",
    "        currency_pair: str,\n",
    "        data_type: str,\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Transform CDD data loaded from S3.\n",
    "\n",
    "        Input data example:\n",
    "        ```\n",
    "        unix           date                 symbol    open     high     low      close    Volume ETH  Volume USDT  tradecount\n",
    "        1631145600000  2021-09-09 00:00:00  ETH/USDT  3499.01  3499.49  3496.17  3496.36  346.4812    1212024      719\n",
    "        1631145660000  2021-09-09 00:01:00  ETH/USDT  3496.36  3501.59  3495.69  3501.59  401.9576    1406241      702\n",
    "        1631145720000  2021-09-09 00:02:00  ETH/USDT  3501.59  3513.10  3499.89  3513.09  579.5656    2032108      1118\n",
    "        ```\n",
    "\n",
    "        Output data example:\n",
    "        ```\n",
    "        timestamp                  open     high     low      close    volume    epoch          currency_pair exchange_id\n",
    "        2021-09-08 20:00:00-04:00  3499.01  3499.49  3496.17  3496.36  346.4812  1631145600000  ETH/USDT      binance\n",
    "        2021-09-08 20:01:00-04:00  3496.36  3501.59  3495.69  3501.59  401.9576  1631145660000  ETH/USDT      binance\n",
    "        2021-09-08 20:02:00-04:00  3501.59  3513.10  3499.89  3513.09  579.5656  1631145720000  ETH/USDT      binance\n",
    "        ```\n",
    "\n",
    "        :param data: dataframe with CDD data from S3\n",
    "        :param exchange_id: CDD exchange id, e.g. \"binance\"\n",
    "        :param currency_pair: currency pair, e.g. \"BTC_USDT\"\n",
    "        :param data_type: OHLCV or trade, bid/ask data\n",
    "        :return: processed dataframe\n",
    "        \"\"\"\n",
    "        transformed_data = self._apply_common_transformation(\n",
    "            data, exchange_id, currency_pair\n",
    "        )\n",
    "        if data_type.lower() == \"ohlcv\":\n",
    "            transformed_data = self._apply_ohlcv_transformation(transformed_data)\n",
    "        else:\n",
    "            hdbg.dfatal(\n",
    "                \"Incorrect data type: '%s'. Acceptable types: '%s'\"\n",
    "                % (data_type.lower(), self._data_types)\n",
    "            )\n",
    "        return transformed_data\n",
    "\n",
    "    def _apply_common_transformation(\n",
    "        self, data: pd.DataFrame, exchange_id: str, currency_pair: str\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Apply transform common to all CDD data.\n",
    "\n",
    "        This includes:\n",
    "        - Datetime format assertion\n",
    "        - Converting string dates to UTC `pd.Timestamp`\n",
    "        - Removing full duplicates\n",
    "        - Resampling to 1 minute using NaNs\n",
    "        - Name volume and currency pair columns properly\n",
    "        - Adding exchange_id and currency_pair columns\n",
    "\n",
    "        :param data: raw data from S3\n",
    "        :param exchange_id: CDD exchange id, e.g. \"binance\"\n",
    "        :param currency_pair: currency pair, e.g. \"BTC_USDT\"\n",
    "        :return: transformed CDD data\n",
    "        \"\"\"\n",
    "        # Verify that the Unix data is provided in ms.\n",
    "        hdbg.dassert_container_type(\n",
    "            data[\"unix\"], container_type=None, elem_type=int\n",
    "        )\n",
    "        # Rename col with original Unix ms epoch.\n",
    "        data = data.rename({\"unix\": \"epoch\"}, axis=1)\n",
    "        # Transform Unix epoch into UTC timestamp.\n",
    "        data[\"timestamp\"] = pd.to_datetime(data[\"epoch\"], unit=\"ms\", utc=True)\n",
    "        #\n",
    "        if self._remove_dups:\n",
    "            # Remove full duplicates.\n",
    "            data = hpandas.drop_duplicates(data, ignore_index=True)\n",
    "        # Set timestamp as index.\n",
    "        data = data.set_index(\"timestamp\")\n",
    "        #\n",
    "        if self._resample_to_1_min:\n",
    "            # Resample to 1 minute.\n",
    "            data = hpandas.resample_df(data, \"T\")\n",
    "        # Rename col with traded volume in amount of the 1st currency in pair.\n",
    "        data = data.rename(\n",
    "            {\"Volume \" + currency_pair.split(\"_\")[0]: \"volume\"}, axis=1\n",
    "        )\n",
    "        # Rename col with currency pair.\n",
    "        data = data.rename({\"symbol\": \"currency_pair\"}, axis=1)\n",
    "        # Add a col with exchange id.\n",
    "        data[\"exchange_id\"] = exchange_id\n",
    "        return data\n",
    "\n",
    "    @staticmethod\n",
    "    def _apply_ohlcv_transformation(data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Apply transformations for OHLCV data.\n",
    "\n",
    "        This includes:\n",
    "        - Assertion of present columns\n",
    "        - Assertion of data types\n",
    "        - Renaming and rearranging of OHLCV columns, namely:\n",
    "            [\"timestamp\",\n",
    "             \"open\",\n",
    "             \"high\",\n",
    "             \"low\",\n",
    "             \"close\"\n",
    "             \"volume\",\n",
    "             \"epoch\",\n",
    "             \"currency_pair\",\n",
    "             \"exchange_id\"]\n",
    "\n",
    "        :param data: data after general CDD transforms\n",
    "        :return: transformed OHLCV dataframe\n",
    "        \"\"\"\n",
    "        ohlcv_columns = [\n",
    "            \"open\",\n",
    "            \"high\",\n",
    "            \"low\",\n",
    "            \"close\",\n",
    "            \"volume\",\n",
    "            \"epoch\",\n",
    "            \"currency_pair\",\n",
    "            \"exchange_id\",\n",
    "        ]\n",
    "        # Verify that dataframe contains OHLCV columns.\n",
    "        hdbg.dassert_is_subset(ohlcv_columns, data.columns)\n",
    "        # Rearrange the columns.\n",
    "        data = data[ohlcv_columns].copy()\n",
    "        return data"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

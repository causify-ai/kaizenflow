{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required imports\n",
    "import sys\n",
    "from operator import add\n",
    "import matplotlib.pyplot as plt\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process streaming data and generate word counts\n",
    "def process_stream(rdd):\n",
    "    if not rdd.isEmpty():\n",
    "        word_counts = rdd.withColumn('word', F.explode(F.col('words_clean'))) \\\n",
    "                         .groupBy('word') \\\n",
    "                         .count() \\\n",
    "                         .sort('count', ascending=False)\n",
    "\n",
    "        # Show the result\n",
    "        word_counts.show()\n",
    "\n",
    "        # Visualize word counts\n",
    "        word_counts_pd = word_counts.limit(10).toPandas()  # Limit to top 10 words for visualization\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.bar(word_counts_pd['word'], word_counts_pd['count'])\n",
    "        plt.xlabel('Words')\n",
    "        plt.ylabel('Count')\n",
    "        plt.title('Top 10 Words in Billboard Songs')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SparkContext and StreamingContext\n",
    "sc = SparkContext(appName=\"RealTimeWordCount\")\n",
    "ssc = StreamingContext(sc, 5)  # 5-second micro-batch interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder.appName(\"PythonWordCount\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV data\n",
    "data = spark.read.format('csv').options(header='true', inferSchema='true') \\\n",
    "    .load('billboard_lyrics_1964-2015.csv')\n",
    "print('############ CSV extract:')\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"Lyrics\", outputCol=\"words_token\")\n",
    "tokenized = tokenizer.transform(data).select('Rank', 'words_token')\n",
    "\n",
    "print('############ Tokenized data extract:')\n",
    "tokenized.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words\n",
    "remover = StopWordsRemover(inputCol='words_token', outputCol='words_clean')\n",
    "data_clean = remover.transform(tokenized).select('Rank', 'words_clean')\n",
    "\n",
    "print('############ Data Cleaning extract:')\n",
    "data_clean.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final word count\n",
    "result = data_clean.withColumn('word', F.explode(F.col('words_clean'))) \\\n",
    "                   .groupBy('word') \\\n",
    "                   .count().sort('count', ascending=False)\n",
    "\n",
    "print('############ Final word count:')\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and remove stop words\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize word counts\n",
    "result_pd = result.limit(10).toPandas()  # Limit to top 10 words for visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(result_pd['word'], result_pd['count'])\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Top 10 Words in Billboard Songs')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DStream by reading text files from the directory\n",
    "data_dir = \"./data_chunks\"\n",
    "stream = ssc.textFileStream(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each RDD in the stream\n",
    "stream.foreachRDD(process_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start streaming\n",
    "ssc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for streaming to finish\n",
    "ssc.awaitTermination()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

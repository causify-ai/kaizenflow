{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0HoQ-_fX9pUL"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/streaming/context.py:72: FutureWarning: DStream is deprecated as of Spark 3.4.0. Migrate to Structured Streaming.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark Streaming context...\n",
      "Awaiting termination...\n",
      "New Batch Arrived!\n",
      "Average characters per Tweet in this batch: 139.58\n",
      "Shortest Tweet in this batch: 21 characters\n",
      "Longest Tweet in this batch: 232 characters\n",
      "\n",
      "New Batch Arrived!\n",
      "Average characters per Tweet in this batch: 135.43\n",
      "Shortest Tweet in this batch: 64 characters\n",
      "Longest Tweet in this batch: 255 characters\n",
      "\n",
      "New Batch Arrived!\n",
      "Average characters per Tweet in this batch: 139.8\n",
      "Shortest Tweet in this batch: 25 characters\n",
      "Longest Tweet in this batch: 248 characters\n",
      "\n",
      "New Batch Arrived!\n",
      "Average characters per Tweet in this batch: 150.46\n",
      "Shortest Tweet in this batch: 22 characters\n",
      "Longest Tweet in this batch: 232 characters\n",
      "\n",
      "New Batch Arrived!\n",
      "Average characters per Tweet in this batch: 143.16\n",
      "Shortest Tweet in this batch: 43 characters\n",
      "Longest Tweet in this batch: 231 characters\n",
      "\n",
      "New Batch Arrived!\n",
      "Average characters per Tweet in this batch: 144.42\n",
      "Shortest Tweet in this batch: 64 characters\n",
      "Longest Tweet in this batch: 228 characters\n",
      "\n",
      "New Batch Arrived!\n",
      "Average characters per Tweet in this batch: 141.34\n",
      "Shortest Tweet in this batch: 52 characters\n",
      "Longest Tweet in this batch: 232 characters\n",
      "\n",
      "New Batch Arrived!\n",
      "Average characters per Tweet in this batch: 136.6\n",
      "Shortest Tweet in this batch: 46 characters\n",
      "Longest Tweet in this batch: 230 characters\n",
      "\n",
      "New Batch Arrived!\n",
      "Average characters per Tweet in this batch: 139.58\n",
      "Shortest Tweet in this batch: 27 characters\n",
      "Longest Tweet in this batch: 215 characters\n",
      "\n",
      "New Batch Arrived!\n",
      "Average characters per Tweet in this batch: 137.08\n",
      "Shortest Tweet in this batch: 18 characters\n",
      "Longest Tweet in this batch: 238 characters\n",
      "\n",
      "All Batches Processed! Run Again for More Data\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Initialize SparkContext and StreamingContext\n",
    "sc = SparkContext(\"local[2]\", \"RandomDataStream\")\n",
    "ssc = StreamingContext(sc, 1)  # Batch interval of 1 second\n",
    "\n",
    "def generate_data():\n",
    "    return [int(np.random.normal(140, 40)) for _ in range(100)]  # Generate 100 random numbers to represent Tweet lengths in characters\n",
    "\n",
    "def process_data(data):\n",
    "    if data.isEmpty():\n",
    "        print(\"All Batches Processed! Run Again for More Data\")\n",
    "        ssc.stop(stopSparkContext=True, stopGraceFully=True)\n",
    "    else:\n",
    "\n",
    "        # Calculate mean\n",
    "        count = data.count()\n",
    "        sum_of_data = data.reduce(lambda x, y: x + y)\n",
    "        mean = sum_of_data / count\n",
    "        print(\"New Batch Arrived!\")\n",
    "        print(\"Average characters per Tweet in this batch:\", mean)\n",
    "\n",
    "        # Calculate min and max\n",
    "        min_val = data.min()\n",
    "        max_val = data.max()\n",
    "        print(f\"Shortest Tweet in this batch: {min_val} characters\")\n",
    "        print(f\"Longest Tweet in this batch: {max_val} characters\\n\")\n",
    "\n",
    "# Create a DStream from generate_data\n",
    "stream = ssc.queueStream([sc.parallelize(generate_data()) for _ in range(10)])\n",
    "\n",
    "# Process the stream\n",
    "stream.foreachRDD(process_data)\n",
    "\n",
    "# Start the streaming context\n",
    "print(\"Starting Spark Streaming context...\")\n",
    "ssc.start()\n",
    "\n",
    "# Wait for the termination of the streaming context\n",
    "print(\"Awaiting termination...\")\n",
    "ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

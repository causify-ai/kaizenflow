################################################################################
system_config
################################################################################
dag_config:
  filter_ath:
    col_mode: replace_all
    transformer_kwargs:
      start_time: 09:30:00
      end_time: 16:00:00
  resample:
    in_col_groups: [('close',), ('volume',), ('feature1',)]
    out_col_group: ()
    transformer_kwargs:
      rule: 5T
      resampling_groups: [({'close': 'close'}, 'last', {}), ({'close': 'twap', 'feature1': 'feature1'}, 'mean', {})]
      vwap_groups: [('close', 'volume', 'vwap')]
    reindex_like_input: False
    join_output_with_input: False
  compute_ret_0:
    in_col_groups: [('close',), ('vwap',), ('twap',)]
    out_col_group: ()
    transformer_kwargs:
      mode: log_rets
    col_mapping:
      close: close.ret_0
      vwap: vwap.ret_0
      twap: twap.ret_0
  compute_vol:
    in_col_group: ('vwap.ret_0',)
    out_col_group: ('vwap.ret_0.vol',)
    drop_nans: True
    permitted_exceptions: (<class 'ValueError'>,)
  adjust_rets:
    in_col_groups: [('vwap.ret_0',), ('vwap.ret_0.vol',)]
    out_col_group: ()
    transformer_kwargs:
      term1_col: vwap.ret_0
      term2_col: vwap.ret_0.vol
      out_col: vwap.ret_0.vol_adj
      term2_delay: 2
      operation: div
    drop_nans: True
  compress_rets:
    in_col_groups: [('vwap.ret_0.vol_adj',)]
    out_col_group: ()
    col_mapping:
      vwap.ret_0.vol_adj: vwap.ret_0.vol_adj.c
dag_builder_object: nid_prefix=
dag_builder_class: Mock1_DagBuilder
system_class: Mock1_Time_ForecastSystem
system_log_dir: $GIT_ROOT/dataflow_amp/system/mock1/test/outcomes/Test_Mock1_Time_ForecastSystem1.test1/tmp.scratch/system_log_dir
market_data_config:
  delay_in_secs: 0
  data:
    index=[2000-01-01 09:31:00-05:00, 2000-01-01 10:30:00-05:00]
    columns=start_datetime,end_datetime,timestamp_db,close,asset_id,volume,feature1
    shape=(60, 7)
                                         start_datetime              end_datetime              timestamp_db  close  asset_id  volume  feature1
    2000-01-01 09:31:00-05:00 2000-01-01 09:30:00-05:00 2000-01-01 09:31:00-05:00 2000-01-01 09:31:00-05:00  101.0       101     100       1.0
    2000-01-01 09:32:00-05:00 2000-01-01 09:31:00-05:00 2000-01-01 09:32:00-05:00 2000-01-01 09:32:00-05:00  101.0       101     100       1.0
    2000-01-01 09:33:00-05:00 2000-01-01 09:32:00-05:00 2000-01-01 09:33:00-05:00 2000-01-01 09:33:00-05:00  101.0       101     100       1.0
    ...
    2000-01-01 10:28:00-05:00 2000-01-01 10:27:00-05:00 2000-01-01 10:28:00-05:00 2000-01-01 10:28:00-05:00  100.0       101     100      -1.0
    2000-01-01 10:29:00-05:00 2000-01-01 10:28:00-05:00 2000-01-01 10:29:00-05:00 2000-01-01 10:29:00-05:00  100.0       101     100      -1.0
    2000-01-01 10:30:00-05:00 2000-01-01 10:29:00-05:00 2000-01-01 10:30:00-05:00 2000-01-01 10:30:00-05:00  100.0       101     100      -1.0
  initial_replayed_delay: 35
  history_lookback: 1 days 00:00:00
dag_runner_config:
  real_time_loop_time_out_in_secs: 900
  sleep_interval_in_secs: 300
event_loop_object: <_EventLoop running=False closed=True debug=False>
market_object: ReplayedMarketData at 0x=(_asset_id_col=asset_id <str>, _asset_ids=[101] <list>, _start_time_col_name=start_datetime <str>, _end_time_col_name=end_datetime <str>, _columns=None <NoneType>, _sleep_in_secs=1.0 <float>, _timezone=America/New_York <str>, _column_remap=None <NoneType>, _filter_data_mode=assert <str>, _max_iterations=120 <int>, _df=pd.df((60, 7) <pandas.core.frame.DataFrame>, _knowledge_datetime_col_name=timestamp_db <str>, _delay_in_secs=0 <int>)
object.str:
  market_object:
    <market_data.replayed_market_data.ReplayedMarketData at 0x>:
      _asset_id_col='asset_id' <str>
      _asset_ids='[101]' <list>
      _start_time_col_name='start_datetime' <str>
      _end_time_col_name='end_datetime' <str>
      _columns='None' <NoneType>
      _sleep_in_secs='1.0' <float>
      _timezone='America/New_York' <str>
      _column_remap='None' <NoneType>
      _filter_data_mode='assert' <str>
      _max_iterations='120' <int>
      _df= <pandas.core.frame.DataFrame>
                                             start_datetime              end_datetime              timestamp_db  close  asset_id  volume  feature1
        2000-01-01 09:31:00-05:00 2000-01-01 09:30:00-05:00 2000-01-01 09:31:00-05:00 2000-01-01 09:31:00-05:00  101.0       101     100       1.0
        2000-01-01 09:32:00-05:00 2000-01-01 09:31:00-05:00 2000-01-01 09:32:00-05:00 2000-01-01 09:32:00-05:00  101.0       101     100       1.0
        2000-01-01 09:33:00-05:00 2000-01-01 09:32:00-05:00 2000-01-01 09:33:00-05:00 2000-01-01 09:33:00-05:00  101.0       101     100       1.0
        ...
        2000-01-01 10:28:00-05:00 2000-01-01 10:27:00-05:00 2000-01-01 10:28:00-05:00 2000-01-01 10:28:00-05:00  100.0       101     100      -1.0
        2000-01-01 10:29:00-05:00 2000-01-01 10:28:00-05:00 2000-01-01 10:29:00-05:00 2000-01-01 10:29:00-05:00  100.0       101     100      -1.0
        2000-01-01 10:30:00-05:00 2000-01-01 10:29:00-05:00 2000-01-01 10:30:00-05:00 2000-01-01 10:30:00-05:00  100.0       101     100      -1.0
      _knowledge_datetime_col_name='timestamp_db' <str>
      _delay_in_secs='0' <int>
  dag_object:
    <dataflow.core.dag.DAG at 0x>:
      _nx_dag='DiGraph with 7 nodes and 6 edges' <networkx.classes.digraph.DiGraph>
      _name='None' <NoneType>
      _mode='strict' <str>
      _save_node_io='' <str>
      _profile_execution='False' <bool>
      _dst_dir='None' <NoneType>
      force_free_nodes='False' <bool>
      nodes=[('filter_ath', {'stage': <dataflow.core.nodes.transformers.ColumnTransformer object at 0x>}), ('resample', {'stage': <dataflow.core.nodes.transformers.GroupedColDfToDfTransformer object at 0x>}), ('compute_ret_0', {'stage': <dataflow.core.nodes.transformers.GroupedColDfToDfTransformer object at 0x>}), ('compute_vol', {'stage': <dataflow.core.nodes.transformers.SeriesToSeriesTransformer object at 0x>}), ('adjust_rets', {'stage': <dataflow.core.nodes.transformers.GroupedColDfToDfTransformer object at 0x>}), ('compress_rets', {'stage': <dataflow.core.nodes.transformers.GroupedColDfToDfTransformer object>}), ('read_data', {'stage': <dataflow.system.source_nodes.RealTimeDataSource object>})]
      edges=[('filter_ath', 'resample', {'df_in': 'df_out'}), ('resample', 'compute_ret_0', {'df_in': 'df_out'}), ('compute_ret_0', 'compute_vol', {'df_in': 'df_out'}), ('compute_vol', 'adjust_rets', {'df_in': 'df_out'}), ('adjust_rets', 'compress_rets', {'df_in': 'df_out'}), ('read_data', 'filter_ath', {'df_in': 'df_out'})]
      json=
      {
          "directed": true,
          "graph": {},
          "links": [
              {
                  "df_in": "df_out",
                  "source": "filter_ath",
                  "target": "resample"
              },
              {
                  "df_in": "df_out",
                  "source": "resample",
                  "target": "compute_ret_0"
              },
              {
                  "df_in": "df_out",
                  "source": "compute_ret_0",
                  "target": "compute_vol"
              },
              {
                  "df_in": "df_out",
                  "source": "compute_vol",
                  "target": "adjust_rets"
              },
              {
                  "df_in": "df_out",
                  "source": "adjust_rets",
                  "target": "compress_rets"
              },
              {
                  "df_in": "df_out",
                  "source": "read_data",
                  "target": "filter_ath"
              }
          ],
          "multigraph": false,
          "nodes": [
              {
                  "id": "filter_ath",
                  "stage": "ColumnTransformer"
              },
              {
                  "id": "resample",
                  "stage": "GroupedColDfToDfTransformer"
              },
              {
                  "id": "compute_ret_0",
                  "stage": "GroupedColDfToDfTransformer"
              },
              {
                  "id": "compute_vol",
                  "stage": "SeriesToSeriesTransformer"
              },
              {
                  "id": "adjust_rets",
                  "stage": "GroupedColDfToDfTransformer"
              },
              {
                  "id": "compress_rets",
                  "stage": "GroupedColDfToDfTransformer"
              },
              {
                  "id": "read_data",
                  "stage": "RealTimeDataSource"
              }
          ]
      }
  dag_runner_object:
    <dataflow.system.real_time_dag_runner.RealTimeDagRunner at 0x>:
      dag= <dataflow.core.dag.DAG>
        <dataflow.core.dag.DAG at 0x>:
          _nx_dag='DiGraph with 7 nodes and 6 edges' <networkx.classes.digraph.DiGraph>
          _name='None' <NoneType>
          _mode='strict' <str>
          _save_node_io='' <str>
          _profile_execution='False' <bool>
          _dst_dir='None' <NoneType>
          force_free_nodes='False' <bool>
          nodes=[('filter_ath', {'stage': <dataflow.core.nodes.transformers.ColumnTransformer object at 0x>}), ('resample', {'stage': <dataflow.core.nodes.transformers.GroupedColDfToDfTransformer object at 0x>}), ('compute_ret_0', {'stage': <dataflow.core.nodes.transformers.GroupedColDfToDfTransformer object at 0x>}), ('compute_vol', {'stage': <dataflow.core.nodes.transformers.SeriesToSeriesTransformer object at 0x>}), ('adjust_rets', {'stage': <dataflow.core.nodes.transformers.GroupedColDfToDfTransformer object at 0x>}), ('compress_rets', {'stage': <dataflow.core.nodes.transformers.GroupedColDfToDfTransformer object>}), ('read_data', {'stage': <dataflow.system.source_nodes.RealTimeDataSource object>})]
          edges=[('filter_ath', 'resample', {'df_in': 'df_out'}), ('resample', 'compute_ret_0', {'df_in': 'df_out'}), ('compute_ret_0', 'compute_vol', {'df_in': 'df_out'}), ('compute_vol', 'adjust_rets', {'df_in': 'df_out'}), ('adjust_rets', 'compress_rets', {'df_in': 'df_out'}), ('read_data', 'filter_ath', {'df_in': 'df_out'})]
          json=
          {
              "directed": true,
              "graph": {},
              "links": [
                  {
                      "df_in": "df_out",
                      "source": "filter_ath",
                      "target": "resample"
                  },
                  {
                      "df_in": "df_out",
                      "source": "resample",
                      "target": "compute_ret_0"
                  },
                  {
                      "df_in": "df_out",
                      "source": "compute_ret_0",
                      "target": "compute_vol"
                  },
                  {
                      "df_in": "df_out",
                      "source": "compute_vol",
                      "target": "adjust_rets"
                  },
                  {
                      "df_in": "df_out",
                      "source": "adjust_rets",
                      "target": "compress_rets"
                  },
                  {
                      "df_in": "df_out",
                      "source": "read_data",
                      "target": "filter_ath"
                  }
              ],
              "multigraph": false,
              "nodes": [
                  {
                      "id": "filter_ath",
                      "stage": "ColumnTransformer"
                  },
                  {
                      "id": "resample",
                      "stage": "GroupedColDfToDfTransformer"
                  },
                  {
                      "id": "compute_ret_0",
                      "stage": "GroupedColDfToDfTransformer"
                  },
                  {
                      "id": "compute_vol",
                      "stage": "SeriesToSeriesTransformer"
                  },
                  {
                      "id": "adjust_rets",
                      "stage": "GroupedColDfToDfTransformer"
                  },
                  {
                      "id": "compress_rets",
                      "stage": "GroupedColDfToDfTransformer"
                  },
                  {
                      "id": "read_data",
                      "stage": "RealTimeDataSource"
                  }
              ]
          }
      config='' <core.config.config_.Config>
      _column_to_tags_mapping='None' <NoneType>
      _result_nid='compress_rets' <str>
      _execute_rt_loop_kwargs= <dict>
        {'get_wall_clock_time': <bound method MarketData.get_wall_clock_time of <market_data.replayed_market_data.ReplayedMarketData at 0x>:
          _asset_id_col='asset_id' <str>
          _asset_ids='[101]' <list>
          _start_time_col_name='start_datetime' <str>
          _end_time_col_name='end_datetime' <str>
          _columns='None' <NoneType>
          _sleep_in_secs='1.0' <float>
          _timezone='America/New_York' <str>
          _column_remap='None' <NoneType>
          _filter_data_mode='assert' <str>
          _max_iterations='120' <int>
          _df= <pandas.core.frame.DataFrame>
                                                 start_datetime              end_datetime              timestamp_db  close  asset_id  volume  feature1
            2000-01-01 09:31:00-05:00 2000-01-01 09:30:00-05:00 2000-01-01 09:31:00-05:00 2000-01-01 09:31:00-05:00  101.0       101     100       1.0
            2000-01-01 09:32:00-05:00 2000-01-01 09:31:00-05:00 2000-01-01 09:32:00-05:00 2000-01-01 09:32:00-05:00  101.0       101     100       1.0
            2000-01-01 09:33:00-05:00 2000-01-01 09:32:00-05:00 2000-01-01 09:33:00-05:00 2000-01-01 09:33:00-05:00  101.0       101     100       1.0
            ...
            2000-01-01 10:28:00-05:00 2000-01-01 10:27:00-05:00 2000-01-01 10:28:00-05:00 2000-01-01 10:28:00-05:00  100.0       101     100      -1.0
            2000-01-01 10:29:00-05:00 2000-01-01 10:28:00-05:00 2000-01-01 10:29:00-05:00 2000-01-01 10:29:00-05:00  100.0       101     100      -1.0
            2000-01-01 10:30:00-05:00 2000-01-01 10:29:00-05:00 2000-01-01 10:30:00-05:00 2000-01-01 10:30:00-05:00  100.0       101     100      -1.0
          _knowledge_datetime_col_name='timestamp_db' <str>
          _delay_in_secs='0' <int>>,
         'sleep_interval_in_secs': 300,
         'time_out_in_secs': 900}
      _dst_dir='None' <NoneType>
      _fit_at_beginning='False' <bool>
      _wake_up_timestamp='None' <NoneType>
      _grid_time_in_secs='300' <int>
      _set_current_bar_timestamp='True' <bool>
      _events='[]' <list>
object.builder_function:
  market_object: dataflow_amp.system.mock1.mock1_forecast_system._get_market_data
  dag_object: dataflow_amp.system.mock1.mock1_forecast_system._get_dag
  dag_runner_object: dataflow_amp.system.mock1.mock1_forecast_system._get_dag_runner
dag_object: DAG at 0x=(_nx_dag=DiGraph with 7 nodes and 6 edges <networkx.classes.digraph.DiGraph>, _name=None <NoneType>, _mode=strict <str>, _save_node_io= <str>, _profile_execution=False <bool>, _dst_dir=None <NoneType>, force_free_nodes=False <bool>)
dag_runner_object:
  RealTimeDagRunner at 0x=(dag=DAG at 0x=(_nx_dag=DiGraph with 7 nodes and 6 edges <networkx.classes.digraph.DiGraph>, _name=None <NoneType>, _mode=strict <str>, _save_node_io= <str>, _profile_execution=False <bool>, _dst_dir=None <NoneType>, force_free_nodes=False <bool>) <dataflow.core.dag.DAG>, config= <core.config.config_.Config>, _column_to_tags_mapping=None <NoneType>, _result_nid=compress_rets <str>, _execute_rt_loop_kwargs={'get_wall_clock_time': <bound method MarketData.get_wall_clock_time of <market_data.replayed_market_data.ReplayedMarketData at 0x>:
    _asset_id_col='asset_id' <str>
    _asset_ids='[101]' <list>
    _start_time_col_name='start_datetime' <str>
    _end_time_col_name='end_datetime' <str>
    _columns='None' <NoneType>
    _sleep_in_secs='1.0' <float>
    _timezone='America/New_York' <str>
    _column_remap='None' <NoneType>
    _filter_data_mode='assert' <str>
    _max_iterations='120' <int>
    _df= <pandas.core.frame.DataFrame>
                                           start_datetime              end_datetime              timestamp_db  close  asset_id  volume  feature1
      2000-01-01 09:31:00-05:00 2000-01-01 09:30:00-05:00 2000-01-01 09:31:00-05:00 2000-01-01 09:31:00-05:00  101.0       101     100       1.0
      2000-01-01 09:32:00-05:00 2000-01-01 09:31:00-05:00 2000-01-01 09:32:00-05:00 2000-01-01 09:32:00-05:00  101.0       101     100       1.0
      2000-01-01 09:33:00-05:00 2000-01-01 09:32:00-05:00 2000-01-01 09:33:00-05:00 2000-01-01 09:33:00-05:00  101.0       101     100       1.0
      ...
      2000-01-01 10:28:00-05:00 2000-01-01 10:27:00-05:00 2000-01-01 10:28:00-05:00 2000-01-01 10:28:00-05:00  100.0       101     100      -1.0
      2000-01-01 10:29:00-05:00 2000-01-01 10:28:00-05:00 2000-01-01 10:29:00-05:00 2000-01-01 10:29:00-05:00  100.0       101     100      -1.0
      2000-01-01 10:30:00-05:00 2000-01-01 10:29:00-05:00 2000-01-01 10:30:00-05:00 2000-01-01 10:30:00-05:00  100.0       101     100      -1.0
    _knowledge_datetime_col_name='timestamp_db' <str>
    _delay_in_secs='0' <int>>, 'sleep_interval_in_secs': 300, 'time_out_in_secs': 900} <dict>, _dst_dir=None <NoneType>, _fit_at_beginning=False <bool>, _wake_up_timestamp=None <NoneType>, _grid_time_in_secs=300 <int>, _set_current_bar_timestamp=True <bool>, _events=[Event(num_it=1, current_time=Timestamp('2000-01-01 10:05:00-0500', tz='America/New_York'), wall_clock_time=Timestamp('xxx', tz='America/New_York')), Event(num_it=2, current_time=Timestamp('2000-01-01 10:10:00-0500', tz='America/New_York'), wall_clock_time=Timestamp('xxx', tz='America/New_York')), Event(num_it=3, current_time=Timestamp('2000-01-01 10:15:00-0500', tz='America/New_York'), wall_clock_time=Timestamp('xxx', tz='America/New_York'))] <list>)
################################################################################
vwap.ret_0.vol_adj.c
################################################################################
                            101
end_datetime
2000-01-01 10:00:00-05:00 -0.98
2000-01-01 10:05:00-05:00  0.98
2000-01-01 10:10:00-05:00 -0.98
2000-01-01 10:15:00-05:00  0.98
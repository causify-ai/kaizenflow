{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f1c0882",
   "metadata": {},
   "source": [
    "# Establish a baseline Poisson Regression Model \n",
    "- Use the International soccer database (ISDB) to predict the goals scored by each team.\n",
    "- Dataset Description:\n",
    "    - `'Date'`: Date on which the match took place.\n",
    "    - `'Sea'` : Describes the yearly season in which the match happened.\n",
    "    - `'Lea'` : League of in which the match is part of.\n",
    "    - `'HT'`  : Home Team.\n",
    "    - `'AT'`  : Away Team.\n",
    "    - `'HS'`  : Goals scored by Home Team.\n",
    "    - `'AS'`  : Goals scored by Away Team.\n",
    "    - `'GD'`  : Goal difference (`HS - AS`)\n",
    "    - `'WDL'` : Match outcome w/r to Home team (home win, home loss, draw)\n",
    "- Use the poisson regressor of the GLM model in stats models\n",
    "- Evaluate the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dac9bd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T21:09:45.292852Z",
     "start_time": "2024-05-31T21:09:40.151684Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import logging\n",
    "from typing import Any, Dict, Iterable, Iterator, List, Optional, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as skm\n",
    "import sklearn.model_selection as sms\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.genmod.generalized_linear_model import GLMResults\n",
    "\n",
    "import helpers.haws as haws\n",
    "import helpers.hdbg as hdbg\n",
    "import research_amp.soccer_prediction.utils as rasoprut\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bb3e4ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T21:09:45.301409Z",
     "start_time": "2024-05-31T21:09:45.297980Z"
    }
   },
   "outputs": [],
   "source": [
    "_LOG = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bd0013c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T21:38:06.839953Z",
     "start_time": "2024-05-31T21:38:06.803350Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_data(df: pd.DataFrame()) -> pd.DataFrame():\n",
    "    \"\"\"\n",
    "    Preprocess the loaded ISDB dataframe of interest.\n",
    "        - Filter and select match from seasons starting from 2009.\n",
    "        - Convert column formats.\n",
    "        - Add epsilon = 0.5 to scores with value as `0` to avoid log(0).\n",
    "        - Check for NaN and infinite values and drop the rows.\n",
    "    \n",
    "    :param df: Input DataFrame. \n",
    "    :return: Preprocessed DataFrame.\n",
    "    \"\"\"\n",
    "    df[\"season\"] = df[\"Sea\"].apply(lambda x: int(\"20\" + str(x)[:2]))\n",
    "    filtered_df = df[df[\"season\"] >= 2009]\n",
    "    # Preprocess the dataset.\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], dayfirst=True)\n",
    "    df.sort_values(by=\"Date\", inplace=True)\n",
    "    # Covert the categorical columns to category type. \n",
    "    categorical_columns = [\"HT\", \"AT\"]\n",
    "    for col in categorical_columns:\n",
    "        filtered_df[col] = filtered_df[col].astype(\"category\")\n",
    "    # Adding a small constant to goals to avoid log(0).\n",
    "    columns = ['AS', 'HS']\n",
    "    epsilon = 0.5\n",
    "    for column in columns:    \n",
    "        filtered_df[column] = filtered_df[column].apply(lambda x: x + epsilon if x == 0 else x)\n",
    "        # Check if there are any infinite or NaN weights and handle them.\n",
    "        if filtered_df.isna().sum().sum() > 0:\n",
    "            _LOG.debug(\"NaN values found in the data. Removing rows with NaNs.\")\n",
    "            filtered_df.dropna(inplace=True)\n",
    "        if filtered_df.isin([-np.inf, np.inf]).sum().sum() > 0:\n",
    "            _LOG.debug(\"Infinite values found in the data. Removing rows with Infs.\")\n",
    "            filtered_df = filtered_df[~np.isinf(filtered_df.select_dtypes(include=[np.number])).any(1)]\n",
    "    # Return the preprocessed DataFrame.\n",
    "    return filtered_df\n",
    "\n",
    "def create_train_test_split(df: pd.DataFrame(), test_size: float = 0.2) -> Dict:\n",
    "    \"\"\"\n",
    "    Create a train-test split with the preprocessed DataFrame. Ensure all the teams are \n",
    "    represented in the training set.\n",
    "    \n",
    "    :param df: Input dataframe.\n",
    "    :return: Dictionary of training and testing DataFrames\n",
    "    \"\"\"\n",
    "   # Ensure reproducibility.\n",
    "    random_state = 42\n",
    "    # Step 1: Split by team to ensure each team is represented in the train split.\n",
    "    teams = df[\"HT\"].unique()\n",
    "    train_indices = []\n",
    "    test_indices = []\n",
    "    for team in teams:\n",
    "        team_df = df[df[\"HT\"] == team]\n",
    "        train_team, test_team = sms.train_test_split(\n",
    "            team_df, test_size=test_size, random_state=random_state\n",
    "                              )\n",
    "        train_indices.extend(train_team.index)\n",
    "        test_indices.extend(test_team.index)\n",
    "    # Create train and test DataFrames.\n",
    "    train_df = df.loc[train_indices]\n",
    "    test_df = df.loc[test_indices] \n",
    "    dataframes = {}\n",
    "    # Add train and test dataframes to the dictionary.\n",
    "    dataframes['train_df'] = train_df\n",
    "    dataframes['test_df'] = test_df\n",
    "    # Return the dictionary of dataframes.\n",
    "    return dataframes\n",
    "\n",
    "def unravel_df(df: pd.DataFrame()) -> pd.DataFrame():\n",
    "    \"\"\"    \n",
    "    Unravel the dataset by creating two entries for each row as team-opponent\n",
    "    pair.\n",
    "    \n",
    "    :param df: Input dataframe.\n",
    "    :return: unraveled dataframe.\n",
    "    \"\"\"\n",
    "    # Create entry for home team `HT`.\n",
    "    home_df = df[[\"Date\", \"Sea\", \"Lge\", \"HT\", \"AT\", \"HS\"]].copy()\n",
    "    home_df.rename(\n",
    "                columns={\"HT\": \"team\", \"AT\": \"opponent\", \"HS\": \"goals\"}, inplace=True\n",
    "                  )\n",
    "    home_df[\"is_home\"] = 1\n",
    "    # Create entry for away team `AT`.\n",
    "    away_df = df[[\"Date\", \"Sea\", \"Lge\", \"HT\", \"AT\", \"AS\"]].copy()\n",
    "    away_df.rename(\n",
    "                columns={\"AT\": \"team\", \"HT\": \"opponent\", \"AS\": \"goals\"}, inplace=True\n",
    "                  )\n",
    "    away_df[\"is_home\"] = 0\n",
    "    # Concatenate the two splits.\n",
    "    unraveled_df = pd.concat([home_df, away_df], ignore_index=True)\n",
    "    # return the unraveled dataframe.\n",
    "    return unraveled_df\n",
    "\n",
    "def representative_sample(df: pd.DataFrame(), sample_size: int) -> pd.DataFrame():\n",
    "    \"\"\"\n",
    "    Function to perform representative sampling on training set to ensure each team is\n",
    "    represented.\n",
    "        \n",
    "    param: df: Input dataframe for sampling.\n",
    "    param: sample_size: Size of the extracted sample (output dataframe).\n",
    "    return: sampled_df: Sampled dataframe.\n",
    "    \"\"\"\n",
    "    # Collect the unique values of teams.\n",
    "    teams = df[\"team\"].unique()\n",
    "    # Identify samples/team.\n",
    "    samples_per_team = sample_size // len(teams)\n",
    "    sampled_df_list = []    \n",
    "    # Iteratively add the samples for each team.\n",
    "    for team in teams:\n",
    "        team_df = df[df[\"team\"] == team]\n",
    "        team_sample = team_df.sample(\n",
    "            n=min(samples_per_team, len(team_df)), random_state=1\n",
    "        )\n",
    "        sampled_df_list.append(team_sample)\n",
    "    # Create a sampled dataframe.    \n",
    "    sampled_df = pd.concat(sampled_df_list)\n",
    "    # Additional random sampling to fill the remaining sample size.\n",
    "    remaining_sample_size = sample_size - len(sampled_df)\n",
    "    if remaining_sample_size > 0:\n",
    "        additional_sample = df.drop(sampled_df.index).sample(\n",
    "            n=remaining_sample_size, random_state=1\n",
    "        )\n",
    "        sampled_df = pd.concat([sampled_df, additional_sample])\n",
    "    # Return the sampled dataframe.\n",
    "    return sampled_df\n",
    "\n",
    "def train_model(train_df: pd.DataFrame(), \n",
    "                logging_level: int = logging.INFO,\n",
    "                **kwargs: Any,\n",
    "               ) -> GLMResults:\n",
    "    \"\"\"\n",
    "    Train a Poisson regression model to estimate the number of goals.\n",
    "    \n",
    "    :param train_df: Input training set.\n",
    "    :return: Trained GLM model.\n",
    "    \"\"\"\n",
    "    # Create the formula to include team offensive and opponent defensive strengths and home advantage.\n",
    "    formula = \"goals ~ C(team) + C(opponent) + is_home\"\n",
    "    # Fit the Poisson regression model.\n",
    "    poisson_model = smf.glm(\n",
    "        formula=formula, data=train_df, family=sm.families.Poisson()\n",
    "    ).fit(maxiter=10)\n",
    "    _LOG.log(logging_level,\n",
    "             poisson_model.summary()\n",
    "            )\n",
    "    # Return the model.\n",
    "    return poisson_model\n",
    "\n",
    "def generate_predictions(model: GLMResults, test_df: pd.DataFrame, **kwargs: Any) -> pd.DataFrame():\n",
    "    \"\"\"\n",
    "    Generated predictions on the test dataset.\n",
    "    \n",
    "    :param model: GLM model to be used.\n",
    "    :param test_df: Test dataset.\n",
    "    :return: Dataframe with predictions.\n",
    "    \"\"\"\n",
    "    # Predict the expected goals for home and away teams in the test set.\n",
    "    test_df[\"predicted_goals\"] = model.predict(test_df)\n",
    "    # Split the dataframe into home and away rows.\n",
    "    home_df = test_df[test_df[\"is_home\"] == 1].copy()\n",
    "    away_df = test_df[test_df[\"is_home\"] == 0].copy()\n",
    "    # Rename columns for merging.\n",
    "    home_df.rename(\n",
    "        columns={\n",
    "            \"team\": \"HT\",\n",
    "            \"opponent\": \"AT\",\n",
    "            \"goals\": \"HS\",\n",
    "            \"predicted_goals\": \"Lambda_HS\",\n",
    "            },\n",
    "        inplace=True,\n",
    "        )\n",
    "    away_df.rename(\n",
    "        columns={\n",
    "            \"team\": \"AT\",\n",
    "            \"opponent\": \"HT\",\n",
    "            \"goals\": \"AS\",\n",
    "            \"predicted_goals\": \"Lambda_AS\",\n",
    "                },\n",
    "        inplace=True,\n",
    "               )\n",
    "    # Merge the home and away dataframes.\n",
    "    merged_df = pd.merge(\n",
    "        home_df,\n",
    "        away_df,\n",
    "        on=[\"Date\", \"Sea\", \"Lge\", \"HT\", \"AT\"],\n",
    "        suffixes=(\"_home\", \"_away\"),\n",
    "    )\n",
    "    # Select and reorder columns for the final dataframe.\n",
    "    test_df = merged_df[[\"Date\", \"Sea\", \"Lge\", \"HT\", \"AT\", \"HS\", \"AS\", \"Lambda_HS\", \"Lambda_AS\"]] \n",
    "    # Return the final dataframe.\n",
    "    return test_df\n",
    "\n",
    "def calculate_match_outcome_probabilities(row: pd.Series()) -> pd.Series():\n",
    "    \"\"\"\n",
    "    Function to calculate match outcome probabilities.\n",
    "    \n",
    "    :param row: Input row on which the match outcomes are calculates.\n",
    "    \"\"\"\n",
    "    # Set maximum score based on the data.\n",
    "    max_goals = 10\n",
    "    # Calculate Poisson probabilities for Home team.\n",
    "    home_goals_probs = [np.exp(-row[\"Lambda_HS\"]) * row[\"Lambda_HS\"] ** i / np.math.factorial(i)\n",
    "                        for i in range(max_goals)\n",
    "                       ]\n",
    "    # Calculate Poisson probabilities for Away team.\n",
    "    away_goals_probs = [np.exp(-row[\"Lambda_AS\"]) * row[\"Lambda_AS\"] ** i / np.math.factorial(i)\n",
    "                        for i in range(max_goals)\n",
    "                       ]\n",
    "    # Calculate the probabilities of winning for home and away.\n",
    "    prob_home_win = 0\n",
    "    prob_away_win = 0\n",
    "    prob_draw = 0\n",
    "    for i in range(max_goals):\n",
    "        for j in range(max_goals):\n",
    "            prob = home_goals_probs[i] * away_goals_probs[j]\n",
    "            if i > j:\n",
    "                prob_home_win += prob\n",
    "            elif i < j:\n",
    "                prob_away_win += prob\n",
    "            else:\n",
    "                prob_draw += prob\n",
    "    probabilities = pd.Series(\n",
    "                        {\"prob_home_win\": prob_home_win,\n",
    "                         \"prob_away_win\": prob_away_win,\n",
    "                         \"prob_draw\": prob_draw,\n",
    "                        }\n",
    "                             )\n",
    "    # Return the calculated Probabilities.\n",
    "    return probabilities\n",
    "\n",
    "def evaluate_model_predictions(test_df: pd.DataFrame()) -> None:\n",
    "    \"\"\"\n",
    "    Evaluate the performance of the model.\n",
    "    \n",
    "    :param test_df: Test Dataframe with the model predictions.\n",
    "    \"\"\"\n",
    "    # Apply the function to the test set.\n",
    "    probabilities = test_df.apply(calculate_match_outcome_probabilities, axis=1)\n",
    "    test_df = pd.concat([test_df, probabilities], axis=1)\n",
    "    # Predict the outcomes based on probabilities.\n",
    "    test_df[\"predicted_outcome\"] = np.where(\n",
    "        test_df[\"prob_home_win\"] > test_df[\"prob_away_win\"],\n",
    "        \"home_win\",\n",
    "        np.where(\n",
    "            test_df[\"prob_away_win\"] > test_df[\"prob_home_win\"], \"away_win\", \"draw\"\n",
    "        ),\n",
    "    )\n",
    "    # Calculate actual outcomes for comparison.\n",
    "    test_df[\"actual_outcome\"] = np.where(\n",
    "        test_df[\"HS\"] > test_df[\"AS\"],\n",
    "        \"home_win\",\n",
    "        np.where(test_df[\"HS\"] < test_df[\"AS\"], \"away_win\", \"draw\"),\n",
    "    )\n",
    "    # Calculate accuracy.\n",
    "    accuracy = skm.accuracy_score(test_df[\"actual_outcome\"], test_df[\"predicted_outcome\"])\n",
    "    print(\"Model Accuracy on Test Set:\", accuracy)\n",
    "    # Round off the predicted goals to integers.\n",
    "    test_df[\"Lambda_HS\"] = test_df[\"Lambda_HS\"].round().astype(int)\n",
    "    test_df[\"Lambda_AS\"] = test_df[\"Lambda_AS\"].round().astype(int)\n",
    "    # Display the test set with probabilities.\n",
    "    print(test_df.head())\n",
    "    # Return the final dataframe\n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd3bdf32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T21:38:06.851937Z",
     "start_time": "2024-05-31T21:38:06.842637Z"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Define the S3 Buckets, dataset path and local directory for download.\n",
    "    bucket = \"cryptokaizen-data-test\"\n",
    "    dataset_path = \"kaizen_ai/soccer_prediction/datasets/OSF_football/\"\n",
    "    local_dir = \"datasets/OSF_football\"\n",
    "    # Download data from S3.\n",
    "    rasoprut.download_data_from_s3(bucket_name = bucket, dataset_path = dataset_path, local_path = local_dir)\n",
    "    # Load the data from S3 into pandas dataframe objects.\n",
    "    dataframes = rasoprut.load_data_to_dataframe(local_path = local_dir)\n",
    "    # Access the dataframes directly from the dictionary.\n",
    "    ISDBv1_df = dataframes.get(\"ISDBv1_df\")\n",
    "    ISDBv2_df = dataframes.get(\"ISDBv2_df\")\n",
    "    # Preprocess the selected dataframe (ISDBv2_df).\n",
    "    preprocessed_df = preprocess_data(ISDBv2_df)\n",
    "    # Create a train-test split. \n",
    "    dataframes_test_train = create_train_test_split(df = preprocessed_df)\n",
    "    # Access the test/train dataframes directly from the dictionary.\n",
    "    train_df = dataframes_test_train.get(\"train_df\")\n",
    "    test_df = dataframes_test_train.get(\"test_df\")\n",
    "    # Unravel the datasets.\n",
    "    unraveled_train_df = unravel_df(train_df)\n",
    "    unraveled_test_df = unravel_df(test_df)\n",
    "    # Create a representative sample of train set and define sample size.\n",
    "    sample_size = int(0.2 * len(unraveled_train_df))\n",
    "    # Perform representative sampling on the training set.\n",
    "    sampled_train_df = representative_sample(df = unraveled_train_df, sample_size = sample_size)\n",
    "    # Train Poisson Regression model.\n",
    "    poisson_model = train_model(sampled_train_df)\n",
    "    # Generate predictions on test set.\n",
    "    predictions_df = generate_predictions(poisson_model, unraveled_test_df)\n",
    "    # Evaluate model predictions.\n",
    "    final_df = evaluate_model_predictions(predictions_df)\n",
    "    # Save dataframe to S3.\n",
    "    final_df.to_csv(\"glm_predictions.csv\", index = False)\n",
    "    save_path = \"kaizen_ai/soccer_predictions/model_output/glm_predictions.csv\"\n",
    "    s3 = haws.get_service_resource(aws_profile=\"ck\", service_name=\"s3\")\n",
    "    # Upload the file to S3\n",
    "    s3.Bucket(bucket).upload_file('glm_predictions.csv', save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba0620cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T21:42:52.811095Z",
     "start_time": "2024-05-31T21:38:06.855386Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy on Test Set: 0.4717499293243407\n",
      "         Date    Sea   Lge         HT          AT   HS   AS  Lambda_HS  \\\n",
      "0  09/11/2013  13-14  GER1  Wolfsburg    Dortmund  2.0  1.0          1   \n",
      "1  25/02/2012  11-12  GER1  Wolfsburg  Hoffenheim  1.0  2.0          2   \n",
      "2  02/02/2013  12-13  GER1  Wolfsburg    Augsburg  1.0  1.0          2   \n",
      "3  21/01/2012  11-12  GER1  Wolfsburg     FC Koln  1.0  0.5          2   \n",
      "4  28/01/2017  16-17  GER1  Wolfsburg    Augsburg  1.0  2.0          2   \n",
      "\n",
      "   Lambda_AS  prob_home_win  prob_away_win  prob_draw predicted_outcome  \\\n",
      "0          2       0.246577       0.537171   0.216204          away_win   \n",
      "1          2       0.457751       0.321579   0.220633          home_win   \n",
      "2          1       0.532794       0.236845   0.230340          home_win   \n",
      "3          1       0.566161       0.216042   0.217757          home_win   \n",
      "4          1       0.532794       0.236845   0.230340          home_win   \n",
      "\n",
      "  actual_outcome  \n",
      "0       home_win  \n",
      "1       away_win  \n",
      "2           draw  \n",
      "3       home_win  \n",
      "4       away_win  \n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

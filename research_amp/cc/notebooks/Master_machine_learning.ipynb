{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54da1cc1",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44249f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import warnings\n",
    "from datetime import timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit, cross_val_score\n",
    "\n",
    "import core.config.config_ as cconconf\n",
    "import core.config.config_utils as ccocouti\n",
    "import core.explore as coexplor\n",
    "import core.features as cofeatur\n",
    "import core.finance.resampling as cfinresa\n",
    "import helpers.hdbg as hdbg\n",
    "import helpers.hpandas as hpandas\n",
    "import helpers.hprint as hprint\n",
    "import helpers.hs3 as hs3\n",
    "import im_v2.crypto_chassis.data.client.crypto_chassis_clients as imvccdcccc\n",
    "import research_amp.cc.crypto_chassis_api as raccchap\n",
    "import research_amp.transform as ramptran\n",
    "import helpers.hparquet as hparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296c560f",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6153685d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbg.init_logger(verbosity=logging.INFO)\n",
    "\n",
    "_LOG = logging.getLogger(__name__)\n",
    "\n",
    "hprint.config_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cde933",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542fec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cmtask1953_config() -> cconconf.Config:\n",
    "    config = cconconf.Config()\n",
    "    param_dict = {\n",
    "        \"data\": {\n",
    "            # Parameters for client initialization.\n",
    "            \"ohlcv_im_client\": {\n",
    "                \"universe_version\": \"v1\",\n",
    "                \"resample_1min\": True,\n",
    "                \"root_dir\": os.path.join(\n",
    "                    #hs3.get_s3_bucket_path(\"ck\"),\n",
    "                    \"s3://cryptokaizen-data\",\n",
    "                    \"reorg\",\n",
    "                    \"historical.manual.pq\",\n",
    "                ),\n",
    "                \"partition_mode\": \"by_year_month\",\n",
    "                \"data_snapshot\": \"latest\",\n",
    "                \"aws_profile\": \"ck\",\n",
    "            },\n",
    "            \"bid_ask_im_client\": {\n",
    "                \"begin_url\": f\"s3://cryptokaizen-data/reorg/historical.manual.pq/20220520/bid_ask/crypto_chassis/binance/currency_pair=BTC_USDT/year=2022/\",\n",
    "                \"aws_profile\": \"ck\",\n",
    "                \"resample_bid_ask\": \"1T\",\n",
    "            },\n",
    "            # Parameters for data query.\n",
    "            \"read_data\": {\n",
    "                \"full_symbols\": [\"binance::BTC_USDT\"],\n",
    "                \"start_ts\": pd.Timestamp(\"2022-01-01 00:00\", tz=\"UTC\"),\n",
    "                \"end_ts\": pd.Timestamp(\"2022-03-31 23:59\", tz=\"UTC\"),\n",
    "                \"columns\": ['close', 'full_symbol', 'volume'],\n",
    "                \"filter_data_mode\": \"assert\",\n",
    "            },\n",
    "        },\n",
    "        \"analysis\": {\n",
    "            \"resampling_rule\": \"5T\",\n",
    "            \"target_value\": \"volume\",\n",
    "        },\n",
    "        \"model\": {\n",
    "            \"delay_lag\": 1,\n",
    "            \"num_lags\": 4,\n",
    "        },\n",
    "    }\n",
    "    config = ccocouti.get_config_from_nested_dict(param_dict)\n",
    "    return config\n",
    "\n",
    "config = get_cmtask1953_config()\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74027f12",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f1fd6d",
   "metadata": {},
   "source": [
    "## OHLCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddd0618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the client.\n",
    "client = imvccdcccc.CryptoChassisHistoricalPqByTileClient(\n",
    "    **config[\"data\"][\"ohlcv_im_client\"]\n",
    ")\n",
    "# Load OHLCV data.\n",
    "# TODO(max): -> df_ohlcv\n",
    "df_ohlcv = client.read_data(**config[\"data\"][\"read_data\"])\n",
    "# Resample.\n",
    "df_ohlcv.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c0fa2b",
   "metadata": {},
   "source": [
    "## Bid ask data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0304ad14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_and_process_bid_ask_data(df, resample_rule):\n",
    "    # Resample.\n",
    "    df = raccchap.resample_bid_ask(\n",
    "        df, resample_rule\n",
    "    )\n",
    "    # Convert.\n",
    "    for cols in df.columns[:-1]:\n",
    "        df[cols] = pd.to_numeric(df[cols], downcast=\"float\")\n",
    "\n",
    "    # Compute bid ask stats.\n",
    "    df = ramptran.calculate_bid_ask_statistics(df)\n",
    "    # Choose only necessary values (`full_symbol`).\n",
    "    df = df.swaplevel(axis=1)[str(config[\"data\"][\"read_data\"][\"full_symbols\"])[\n",
    "    2:-2\n",
    "]][\n",
    "        [\"bid_size\", \"ask_size\", \"bid_price\", \"ask_price\", \"mid\", \"quoted_spread\"]\n",
    "    ]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51d8ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = config[\"data\"][\"read_data\"][\"start_ts\"]\n",
    "end_date = config[\"data\"][\"read_data\"][\"end_ts\"]\n",
    "\n",
    "# Load bid ask from s3. Note: works only for 2022 for now.\n",
    "# TODO(Grisha, Dan): How to load the bid/ask data through ImClient?\n",
    "result = []\n",
    "\n",
    "for i in range(start_date.month, end_date.month + 1):\n",
    "    print(i)\n",
    "    tmp_df = hparquet.from_parquet(\n",
    "        os.path.join(config[\"data\"][\"bid_ask_im_client\"][\"begin_url\"], f\"month={i}/data.parquet\"), \n",
    "        aws_profile=config[\"data\"][\"bid_ask_im_client\"][\"aws_profile\"]\n",
    "    )\n",
    "    result.append(tmp_df)\n",
    "bid_ask_df = pd.concat(result)\n",
    "bid_ask_df = bid_ask_df[:end_date]\n",
    "# Add `full_symbol` (necessary param for `calculate_bid_ask_statistics`).\n",
    "bid_ask_df[\"full_symbol\"] = str(config[\"data\"][\"read_data\"][\"full_symbols\"])[\n",
    "    2:-2\n",
    "]\n",
    "# Choose only valid cols.\n",
    "bid_ask_df = bid_ask_df[\n",
    "    [\"bid_price\", \"bid_size\", \"ask_price\", \"ask_size\", \"full_symbol\"]\n",
    "]\n",
    "# Resample to 1-min (to be consistent with OHLCV data).\n",
    "bid_ask_df_1min = resample_and_process_bid_ask_data(bid_ask_df, config[\"data\"][\"bid_ask_im_client\"][\"resample_bid_ask\"])\n",
    "\n",
    "bid_ask_df_1min.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3aad4de",
   "metadata": {},
   "source": [
    "## Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73201765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHLCV + bid ask\n",
    "data = pd.concat([df_ohlcv, bid_ask_df_1min], axis=1)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace30295",
   "metadata": {},
   "source": [
    "# Create and test functions for each estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2bd409",
   "metadata": {},
   "source": [
    "## Estimate intraday spread, volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335e291e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_value(df: pd.DataFrame, timestamp: pd.Timestamp, column_name: str):\n",
    "    \"\"\"\n",
    "    :param df: data that contains spread and/or volume\n",
    "    :param timestamp: timestamp for prediciton\n",
    "    :param column_name: targeted estimation value (e.g., \"quoted_spread\", \"volume\")\n",
    "    :return: value of targeted spread or volume\n",
    "    \"\"\"\n",
    "    hpandas.dassert_monotonic_index(df.index)\n",
    "    if timestamp >= df.index.min() and timestamp <= df.index.max():\n",
    "        value = df[column_name].loc[timestamp]\n",
    "    else:\n",
    "        value = np.nan\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7784353",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = pd.Timestamp(\"2022-01-01 00:00\", tz=\"UTC\")\n",
    "display(get_target_value(data, date, \"quoted_spread\"))\n",
    "display(get_target_value(data, date, \"volume\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57e0fe1",
   "metadata": {},
   "source": [
    "## Naive estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0536d5",
   "metadata": {},
   "source": [
    "Value(t+2) = Value(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59416f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(max): delete this guy, because we will use lags \n",
    "def get_naive_value(\n",
    "    df: pd.DataFrame,\n",
    "    timestamp: pd.Timestamp,\n",
    "    column_name: str,\n",
    "    delay_in_mins: int = 2,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Estimator for a given time is a `t - delay_in_mins` of a real value.\n",
    "\n",
    "    :param df: data that contains spread and/or volume\n",
    "    :param timestamp: timestamp for prediciton\n",
    "    :param column_name: targeted estimation value (e.g., \"quoted_spread\", \"volume\")\n",
    "    :param delay_in_mins: desired gap for target estimator, in mins\n",
    "    :return: value of predicted spread or volume\n",
    "    \"\"\"\n",
    "    # Check and define delay.\n",
    "    hdbg.dassert_lte(1, delay_in_mins)\n",
    "    delay_in_mins = timedelta(minutes=delay_in_mins)\n",
    "    # Get the value.\n",
    "    lookup_timestamp = timestamp - delay_in_mins\n",
    "    if lookup_timestamp >= df.index.min() and lookup_timestamp <= df.index.max():\n",
    "        value = get_target_value(df, lookup_timestamp, column_name)\n",
    "    else:\n",
    "        value = np.nan\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94eec9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = pd.Timestamp(\"2022-01-01 10:00\", tz=\"UTC\")\n",
    "display(get_naive_value(data, date, \"quoted_spread\", delay_in_mins=10))\n",
    "display(get_naive_value(data, date, \"volume\", delay_in_mins=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee476ef0",
   "metadata": {},
   "source": [
    "## Look back N days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85269e03",
   "metadata": {},
   "source": [
    "spread_lookback(t) = E_date[spread(t, date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52366786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column with intraday time.\n",
    "data[\"time\"] = data.index.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b46e4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(max): -> get_average_intraday_value\n",
    "# TODO(max): This is a feature specific of volume, spread, and volatility (not useful for returns)\n",
    "def get_lookback_value(\n",
    "    df: pd.DataFrame,\n",
    "    timestamp: pd.Timestamp,\n",
    "    lookback_days: int,\n",
    "    column_name: str,\n",
    "    delay: int = 0,\n",
    "    mode: str = \"mean\",\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    1) Set the period that is equal `timestamp for prediciton` - N days (lookback_days).\n",
    "    2) For that period, calculate mean (or median) value for spread in time during days.\n",
    "    3) Choose this mean value as an estimation for spread in the given timestamp.\n",
    "\n",
    "    :param df: data that contains spread\n",
    "    :param timestamp: timestamp for prediciton\n",
    "    :param lookback_days: historical period for estimation, in days\n",
    "    :param column_name: targeted estimation value (e.g., \"quoted_spread\", \"volume\")\n",
    "    :param delay: how many minutes to substract from the lookback starting period\n",
    "    :param mode: 'mean' or 'median'\n",
    "    :return: value of predicted spread\n",
    "    \"\"\"\n",
    "    # Choose sample data using lookback period (with a delay).\n",
    "    start_date = timestamp - timedelta(days=lookback_days, minutes=delay)\n",
    "    if start_date >= df.index.min() and start_date <= df.index.max():\n",
    "        sample = df.loc[start_date:timestamp].loc[timestamp.time()]\n",
    "        if mode == \"mean\":\n",
    "            value = sample[column_name].mean()\n",
    "        else:\n",
    "            value = sample[column_name].median()\n",
    "    else:\n",
    "        value = np.nan\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c08371",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = pd.Timestamp(\"2022-01-21 19:00\", tz=\"UTC\")\n",
    "display(get_lookback_value(data, date, 14, \"quoted_spread\"))\n",
    "display(get_lookback_value(data, date, 14, \"volume\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d6e6de",
   "metadata": {},
   "source": [
    "# Collect all estimators for the whole period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661702ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attach_resampled_y_var(resampled_df, estimators_df, target):\n",
    "    if target == \"spread\":\n",
    "        # Choose Y-var.\n",
    "        resampled_df = resampled_df[[f\"quoted_{target}\"]]\n",
    "        # Rename Y-var.\n",
    "        resampled_df = resampled_df.rename(columns={\"quoted_spread\": \"real_spread_0\"})\n",
    "    elif target == \"volume\":\n",
    "        # Choose Y-var.\n",
    "        resampled_df = resampled_df[[f\"{target}\"]]\n",
    "        # Rename Y-var.\n",
    "        resampled_df = resampled_df.rename(columns={\"volume\": \"real_volume_0\"})\n",
    "    # Attach Y-var to the computed estimators.\n",
    "    yx_df = pd.merge(resampled_df, estimators_df, left_index=True, right_index=True)\n",
    "    return yx_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff993115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is building the ml_df\n",
    "# the predicted var is always y\n",
    "# compute lags\n",
    "# add the median feature\n",
    "target = config[\"analysis\"][\"target_value\"]\n",
    "# Add initial target values.\n",
    "estimators = data[[target]]\n",
    "estimators.columns =  [f\"real_{target}_0\"]\n",
    "# Add lagged values.\n",
    "delay_lag = config[\"model\"][\"delay_lag\"]\n",
    "num_lags = config[\"model\"][\"num_lags\"]\n",
    "estimators, info = cofeatur.compute_lagged_features(\n",
    "    estimators, f\"real_{target}_0\", delay_lag, num_lags\n",
    ")\n",
    "# Add lookback estimator.\n",
    "estimators[f\"lookback_{target}\"] = estimators.index\n",
    "estimators[f\"lookback_{target}\"] = estimators[f\"lookback_{target}\"].apply(lambda x: get_lookback_value(data, \n",
    "                                                                                                         x, \n",
    "                                                                                                         14, \n",
    "                                                                                                         target))\n",
    "# Drop the column with real_0, since Y-var will be added later (resampled).\n",
    "estimators=estimators.drop(columns=f\"real_{target}_0\")\n",
    "estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64154228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample bid ask.\n",
    "bid_ask_df_5min = resample_and_process_bid_ask_data(bid_ask_df, \"5T\")\n",
    "# Resample OHLCV\n",
    "df_ohlcv_5min = df_ohlcv.resample(\"5T\").agg({\n",
    "    \"close\": \"last\",\n",
    "    \"volume\": \"sum\"\n",
    "})\n",
    "\n",
    "df_5min = pd.concat([df_ohlcv_5min, bid_ask_df_5min],axis=1)\n",
    "\n",
    "est_df = attach_resampled_y_var(df_5min, estimators, target)\n",
    "\n",
    "est_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d005654f",
   "metadata": {},
   "source": [
    "# Predict via sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8953538",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd42e93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_results(y_true, y_pred, mae_only: bool = True):\n",
    "    # Regression metrics\n",
    "    mean_absolute_error = metrics.mean_absolute_error(y_true, y_pred)\n",
    "    print(\"MAE: \", round(mean_absolute_error, 4))\n",
    "    if not mae_only:\n",
    "        explained_variance = metrics.explained_variance_score(y_true, y_pred)\n",
    "        mse = metrics.mean_squared_error(y_true, y_pred)\n",
    "        mean_squared_log_error = metrics.mean_squared_log_error(y_true, y_pred)\n",
    "        metrics.median_absolute_error(y_true, y_pred)\n",
    "        r2 = metrics.r2_score(y_true, y_pred)\n",
    "        print(\"mean_squared_log_error: \", round(mean_squared_log_error, 4))\n",
    "        print(\"explained_variance: \", round(explained_variance, 4))\n",
    "        print(\"r2: \", round(r2, 4))\n",
    "        print(\"MAE: \", round(mean_absolute_error, 4))\n",
    "        print(\"MSE: \", round(mse, 4))\n",
    "        print(\"RMSE: \", round(np.sqrt(mse), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f0d3fc",
   "metadata": {},
   "source": [
    "## Defining training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f62c172",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_df = hpandas.dropna(est_df)\n",
    "display(ml_df.shape)\n",
    "display(ml_df.head(3))\n",
    "print(f\"Set of prediciton features = {list(ml_df.columns[1:])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3c7887",
   "metadata": {},
   "source": [
    "## Train / test data separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a04074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(max): Use time series splits vs train/test\n",
    "start_test = ml_df.index[0].date()\n",
    "end_test = ml_df.index[-1].date()\n",
    "\n",
    "# Training dataset.\n",
    "X_train = ml_df.loc[start_test:\"2022-03-24\"].drop([f\"real_{target}_0\"], axis=1)\n",
    "y_train = ml_df.loc[start_test:\"2022-03-24\", f\"real_{target}_0\"]\n",
    "\n",
    "# Testing dataset.\n",
    "X_test = ml_df.loc[\"2022-03-25\":end_test].drop([f\"real_{target}_0\"], axis=1)\n",
    "y_test = ml_df.loc[\"2022-03-25\":end_test, f\"real_{target}_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e24d6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = (X_train.index.max() - X_train.index.min()).days + 1\n",
    "print(n_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5c7bd6",
   "metadata": {},
   "source": [
    "## Models Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b1c6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of various estimation modes.\n",
    "models = []\n",
    "models.append((\"LR\", LinearRegression()))\n",
    "# models.append((\"NN\", MLPRegressor(solver=\"lbfgs\")))  # neural network\n",
    "# models.append((\"KNN\", KNeighborsRegressor()))\n",
    "# models.append(\n",
    "#    (\"RF\", RandomForestRegressor(n_estimators=10))\n",
    "# )  # Ensemble method - collection of many decision trees\n",
    "# models.append((\"SVR\", SVR(gamma=\"auto\")))  # kernel = linear\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783f84fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "results_stats = pd.DataFrame()\n",
    "for name, model in models:\n",
    "    # TimeSeries Cross validation\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=tscv, scoring=\"r2\")\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print(\"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std()))\n",
    "\n",
    "    results_stats.loc[name, \"mean_perf\"] = cv_results.mean()\n",
    "    results_stats.loc[name, \"std_dev_perf\"] = cv_results.std()\n",
    "\n",
    "display(results_stats.sort_values(\"mean_perf\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527b5e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "plt.boxplot(results, labels=names)\n",
    "plt.title(\"Algorithm Comparison\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fb5ac3",
   "metadata": {},
   "source": [
    "### Grid Searching Hyperparameters (LinearRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a99c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model param variations.\n",
    "model = LinearRegression()\n",
    "param_search = {\n",
    "    \"fit_intercept\": [True, False],\n",
    "    \"normalize\": [True, False],\n",
    "    \"n_jobs\": [1, 20, 50],\n",
    "    \"positive\": [True, False],\n",
    "}\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "# If scoring = None, the estimator's score method is used.\n",
    "\n",
    "# Run the model with different param variations.\n",
    "gsearch = GridSearchCV(\n",
    "    estimator=model,\n",
    "    cv=tscv,\n",
    "    param_grid=param_search,\n",
    ")\n",
    "gsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9703717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results of the best param fit.\n",
    "best_score = gsearch.best_score_\n",
    "best_model = gsearch.best_estimator_\n",
    "display(best_score)\n",
    "display(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221049b0",
   "metadata": {},
   "source": [
    "#### Evaluate results using testing sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9367f397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate testing results.\n",
    "y_true = y_test.values\n",
    "y_pred = best_model.predict(X_test)\n",
    "regression_results(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5868bf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check coefficients.\n",
    "coef = pd.DataFrame(\n",
    "    {\"coef_value\": best_model.coef_}, index=best_model.feature_names_in_\n",
    ")\n",
    "coef = coef.sort_values(by=\"coef_value\", ascending=False)\n",
    "coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67de5b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results of predicting on testing sample.\n",
    "lr_test = pd.concat([pd.Series(y_true), pd.Series(y_pred)], axis=1)\n",
    "lr_test.columns = [\"true\", \"predicted\"]\n",
    "lr_test.index = y_test.index\n",
    "lr_test.plot(figsize=(15, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0619a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the difference between true and predicted values.\n",
    "lr_test[\"diff\"] = lr_test[\"true\"] - lr_test[\"predicted\"]\n",
    "lr_test[\"diff\"].plot(figsize=(15, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf97150",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9b679c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

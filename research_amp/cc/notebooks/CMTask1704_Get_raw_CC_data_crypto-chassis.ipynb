{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58d76abe",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d2298b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "import core.config.config_ as cconconf\n",
    "import core.finance as cofinanc\n",
    "import core.finance.bid_ask as cfibiask\n",
    "import core.finance.resampling as cfinresa\n",
    "import core.plotting.normality as cplonorm\n",
    "import dataflow.core as dtfcore\n",
    "import dataflow.system.source_nodes as dtfsysonod\n",
    "import helpers.hdatetime as hdateti\n",
    "import helpers.hdbg as hdbg\n",
    "import helpers.hprint as hprint\n",
    "import helpers.hsql as hsql\n",
    "import im_v2.ccxt.data.client as icdcl\n",
    "import im_v2.im_lib_tasks as imvimlita\n",
    "import im_v2.talos.data.client.talos_clients as imvtdctacl\n",
    "\n",
    "import im_v2.common.universe as ivcu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb220a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbg.init_logger(verbosity=logging.INFO)\n",
    "\n",
    "_LOG = logging.getLogger(__name__)\n",
    "\n",
    "hprint.config_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea446ce",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0680e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cmtask1704_config_ccxt() -> cconconf.Config:\n",
    "    \"\"\"\n",
    "    Get config, that specifies params for getting raw data.\n",
    "    \"\"\"\n",
    "    config = cconconf.Config()\n",
    "    # Load parameters.\n",
    "    #config.add_subconfig(\"load\")\n",
    "    #env_file = imvimlita.get_db_env_path(\"dev\")\n",
    "    #connection_params = hsql.get_connection_info_from_env_file(env_file)\n",
    "    #config[\"load\"][\"connection\"] = hsql.get_connection(*connection_params)\n",
    "    #config[\"load\"][\"aws_profile\"] = \"ck\"\n",
    "    #config[\"load\"][\"data_dir_hist\"] = os.path.join(\n",
    "    #    \"s3://cryptokaizen-data\", \"historical\"\n",
    "    #)\n",
    "    #config[\"load\"][\"data_snapshot\"] = \"latest\"\n",
    "    #config[\"load\"][\"partition_mode\"] = \"by_year_month\"\n",
    "    # Data parameters.\n",
    "    config.add_subconfig(\"data\")\n",
    "    config[\"data\"][\"full_symbols\"] = ['binance::BNB_USDT', 'binance::BTC_USDT']\n",
    "    # Data range for real-time data.\n",
    "    #config[\"data\"][\"start_date_rt\"] = pd.Timestamp(\"2022-04-01\", tz=\"UTC\")\n",
    "    #config[\"data\"][\"end_date_rt\"] = pd.Timestamp(\"2022-04-15\", tz=\"UTC\")\n",
    "    # Data range for historical data.\n",
    "    config[\"data\"][\"start_date\"] = pd.Timestamp(\"2022-01-01\", tz=\"UTC\")\n",
    "    config[\"data\"][\"end_date\"] = pd.Timestamp(\"2022-01-15\", tz=\"UTC\")\n",
    "    # Transformation parameters.\n",
    "    config.add_subconfig(\"transform\")\n",
    "    config[\"transform\"][\"resampling_rule\"] = \"5T\"\n",
    "    config[\"transform\"][\"rets_type\"] = \"pct_change\"\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dae195",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_cmtask1704_config_ccxt()\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9eef66",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340a263b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vwap_twap(df: pd.DataFrame, resampling_rule: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Resample the data and calculate VWAP, TWAP using DataFlow methods.\n",
    "\n",
    "    :param df: Raw data\n",
    "    :param resampling_rule: Desired resampling frequency\n",
    "    :return: Resampled multiindex DataFrame with computed metrics\n",
    "    \"\"\"\n",
    "    # Configure the node to do the TWAP / VWAP resampling.\n",
    "    node_resampling_config = {\n",
    "        \"in_col_groups\": [\n",
    "            (\"close\",),\n",
    "            (\"volume\",),\n",
    "        ],\n",
    "        \"out_col_group\": (),\n",
    "        \"transformer_kwargs\": {\n",
    "            \"rule\": resampling_rule,\n",
    "            \"resampling_groups\": [\n",
    "                ({\"close\": \"close\"}, \"last\", {}),\n",
    "                (\n",
    "                    {\n",
    "                        \"close\": \"twap\",\n",
    "                    },\n",
    "                    \"mean\",\n",
    "                    {},\n",
    "                ),\n",
    "                (\n",
    "                    {\n",
    "                        \"volume\": \"volume\",\n",
    "                    },\n",
    "                    \"sum\",\n",
    "                    {\"min_count\": 1},\n",
    "                ),\n",
    "            ],\n",
    "            \"vwap_groups\": [\n",
    "                (\"close\", \"volume\", \"vwap\"),\n",
    "            ],\n",
    "        },\n",
    "        \"reindex_like_input\": False,\n",
    "        \"join_output_with_input\": False,\n",
    "    }\n",
    "    # Put the data in the DataFlow format (which is multi-index).\n",
    "    converted_data = dtfsysonod._convert_to_multiindex(df, \"full_symbol\")\n",
    "    # Create the node.\n",
    "    nid = \"resample\"\n",
    "    node = dtfcore.GroupedColDfToDfTransformer(\n",
    "        nid,\n",
    "        transformer_func=cofinanc.resample_bars,\n",
    "        **node_resampling_config,\n",
    "    )\n",
    "    # Compute the node on the data.\n",
    "    vwap_twap = node.fit(converted_data)\n",
    "    # Save the result.\n",
    "    vwap_twap_df = vwap_twap[\"df_out\"]\n",
    "    return vwap_twap_df\n",
    "\n",
    "def calculate_returns(df: pd.DataFrame, rets_type: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute returns on the resampled data DataFlow-style.\n",
    "\n",
    "    :param df: Resampled multiindex DataFrame\n",
    "    :param rets_type: i.e., \"log_rets\" or \"pct_change\"\n",
    "    :return: The same DataFrame but with attached columns with returns\n",
    "    \"\"\"\n",
    "    # Configure the node to calculate the returns.\n",
    "    node_returns_config = {\n",
    "        \"in_col_groups\": [\n",
    "            (\"close\",),\n",
    "            (\"vwap\",),\n",
    "            (\"twap\",),\n",
    "        ],\n",
    "        \"out_col_group\": (),\n",
    "        \"transformer_kwargs\": {\n",
    "            \"mode\": rets_type,\n",
    "        },\n",
    "        \"col_mapping\": {\n",
    "            \"close\": \"close.ret_0\",\n",
    "            \"vwap\": \"vwap.ret_0\",\n",
    "            \"twap\": \"twap.ret_0\",\n",
    "        },\n",
    "    }\n",
    "    # Create the node that computes ret_0.\n",
    "    nid = \"ret0\"\n",
    "    node = dtfcore.GroupedColDfToDfTransformer(\n",
    "        nid,\n",
    "        transformer_func=cofinanc.compute_ret_0,\n",
    "        **node_returns_config,\n",
    "    )\n",
    "    # Compute the node on the data.\n",
    "    rets = node.fit(df)\n",
    "    # Save the result.\n",
    "    rets_df = rets[\"df_out\"]\n",
    "    return rets_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b068ea0",
   "metadata": {},
   "source": [
    "# Load OHLCV data from `crypto-chassis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a83682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(Max): Refactor the loading part once #1766 is implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f09ab9f",
   "metadata": {},
   "source": [
    "## Functions to extract and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e386b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_crypto_chassis_ohlcv_for_one_symbol(full_symbol):\n",
    "    \"\"\"\n",
    "    - Transform CK `full_symbol` to the `crypto-chassis` request format.\n",
    "    - Construct OHLCV data request for `crypto-chassis` API.\n",
    "    - Save the data as a DataFrame.\n",
    "    \"\"\"\n",
    "    # Deconstruct `full_symbol`.\n",
    "    cc_exchange_id, cc_currency_pair = ivcu.parse_full_symbol(full_symbol)\n",
    "    cc_currency_pair = cc_currency_pair.lower().replace(\"_\", \"-\")\n",
    "    # Build a request.\n",
    "    r = requests.get(\n",
    "        f\"https://api.cryptochassis.com/v1/ohlc/{cc_exchange_id}/{cc_currency_pair}?startTime=0\"\n",
    "    )\n",
    "    # Get url with data.\n",
    "    url = r.json()[\"historical\"][\"urls\"][0][\"url\"]\n",
    "    # Read the data.\n",
    "    df = pd.read_csv(url, compression=\"gzip\")\n",
    "    return df\n",
    "\n",
    "def apply_ohlcv_transformation(df, full_symbol, start_date, end_date):\n",
    "    \"\"\"\n",
    "    The following transformations are applied:\n",
    "    - Convert `timestamps` to the usual format.\n",
    "    - Convert data columns to `float`.\n",
    "    - Add `full_symbol` column.\n",
    "    \"\"\"\n",
    "    # Convert `timestamps` to the usual format.\n",
    "    df = df.rename(columns={\"time_seconds\": \"timestamp\"})\n",
    "    df[\"timestamp\"] = df[\"timestamp\"].apply(\n",
    "        lambda x: hdateti.convert_unix_epoch_to_timestamp(x, unit=\"s\")\n",
    "    )\n",
    "    df = df.set_index(\"timestamp\")\n",
    "    # Convert to `float`.\n",
    "    for cols in df.columns:\n",
    "        df[cols] = df[cols].astype(float)\n",
    "    # Add `full_symbol`.\n",
    "    df[\"full_symbol\"] = full_symbol\n",
    "    # Note: I failed to put [start_time, end_time] to historical request.\n",
    "    # Now it loads all the available data.\n",
    "    # For that reason the time interval is hardcoded on this stage.\n",
    "    df = df.loc[(df.index>=start_date)&(df.index<=end_date)]\n",
    "    return df\n",
    "\n",
    "def read_crypto_chassis_ohlcv(full_symbols, start_date, end_date):\n",
    "    \"\"\"\n",
    "    - Load the raw data for one symbol.\n",
    "    - Convert it to CK format.\n",
    "    - Repeat the first two steps for all `full_symbols`.\n",
    "    - Concentrate them into unique DataFrame.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for full_symbol in full_symbols:\n",
    "        # Load raw data.\n",
    "        df_raw = load_crypto_chassis_ohlcv_for_one_symbol(full_symbol)\n",
    "        # Process it to CK format.\n",
    "        df = apply_ohlcv_transformation(df_raw, full_symbol, start_date, end_date)\n",
    "        result.append(df)\n",
    "    final_df = pd.concat(result)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7dabf8",
   "metadata": {},
   "source": [
    "## Data demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe48240",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_symbols = config[\"data\"][\"full_symbols\"]\n",
    "start_date = config[\"data\"][\"start_date\"]\n",
    "end_date = config[\"data\"][\"end_date\"]\n",
    "\n",
    "\n",
    "ohlcv_cc = read_crypto_chassis_ohlcv(full_symbols, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af803201",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohlcv_cc.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbccce83",
   "metadata": {},
   "source": [
    "# Calculate VWAP, TWAP and returns in `Dataflow` style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc305d6c",
   "metadata": {},
   "source": [
    "## CCXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f8eb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VWAP, TWAP transformation.\n",
    "resampling_rule = config[\"transform\"][\"resampling_rule\"]\n",
    "vwap_twap_df = calculate_vwap_twap(ohlcv_cc, resampling_rule)\n",
    "\n",
    "# Returns calculation.\n",
    "rets_type = config[\"transform\"][\"rets_type\"]\n",
    "vwap_twap_rets_df = calculate_returns(vwap_twap_df, rets_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa23e95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the snippet.\n",
    "vwap_twap_rets_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556c808e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats and vizualisation to check the outcomes.\n",
    "bnb_ex = vwap_twap_rets_df.swaplevel(axis=1)\n",
    "bnb_ex = bnb_ex[\"binance::BNB_USDT\"][[\"close.ret_0\", \"twap.ret_0\", \"vwap.ret_0\"]]\n",
    "display(bnb_ex.corr())\n",
    "bnb_ex.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc86ee7",
   "metadata": {},
   "source": [
    "# Bid-ask data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2882f2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(Max): Refactor the loading part once #1766 is implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e9844e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to deal with `crypto-chassis` data.\n",
    "def load_bid_ask_data(exchange_id, currency_pair, list_of_dates):\n",
    "    # Using the variables from `datelist` the multiple requests can be sent to the API.\n",
    "    result = []\n",
    "    for date in list_of_dates:\n",
    "        # Interaction with the API.\n",
    "        r = requests.get(\n",
    "            f\"https://api.cryptochassis.com/v1/market-depth/{exchange_id}/{currency_pair}?startTime={date}\"\n",
    "        )\n",
    "        data = pd.read_csv(r.json()[\"urls\"][0][\"url\"], compression=\"gzip\")\n",
    "        # Attaching it day-by-day to the final DataFrame.\n",
    "        result.append(data)\n",
    "    bid_ask_df = pd.concat(result)\n",
    "    return bid_ask_df\n",
    "\n",
    "def clean_up_raw_bid_ask_data(df, full_symbol):\n",
    "    # Split the columns to differentiate between `price` and `size`.\n",
    "    df[[\"bid_price\", \"bid_size\"]] = df[\"bid_price_bid_size\"].str.split(\n",
    "        \"_\", expand=True\n",
    "    )\n",
    "    df[[\"ask_price\", \"ask_size\"]] = df[\"ask_price_ask_size\"].str.split(\n",
    "        \"_\", expand=True\n",
    "    )\n",
    "    df = df.drop(columns=[\"bid_price_bid_size\", \"ask_price_ask_size\"])\n",
    "    # Convert `timestamps` to the usual format.\n",
    "    df = df.rename(columns={\"time_seconds\": \"timestamp\"})\n",
    "    df[\"timestamp\"] = df[\"timestamp\"].apply(\n",
    "        lambda x: hdateti.convert_unix_epoch_to_timestamp(x, unit=\"s\")\n",
    "    )\n",
    "    df = df.set_index(\"timestamp\")\n",
    "    # Convert to `float`.\n",
    "    for cols in df.columns:\n",
    "        df[cols] = df[cols].astype(float)\n",
    "    # Add `full_symbol` (hardcoded solution).\n",
    "    df[\"full_symbol\"] = full_symbol\n",
    "    return df\n",
    "\n",
    "def resample_bid_ask(df, resampling_rule):\n",
    "    \"\"\"\n",
    "    In the current format the data is presented in the `seconds` frequency. In\n",
    "    order to convert it to the minutely (or other) frequencies the following\n",
    "    aggregation rules are applied:\n",
    "\n",
    "    - Size is the sum of all sizes during the resampling period\n",
    "    - Price is the mean of all prices during the resampling period\n",
    "    \"\"\"\n",
    "    new_df = cfinresa.resample(df, rule=resampling_rule).agg(\n",
    "        {\n",
    "            \"bid_price\": \"mean\",\n",
    "            \"bid_size\": \"sum\",\n",
    "            \"ask_price\": \"mean\",\n",
    "            \"ask_size\": \"sum\",\n",
    "            \"full_symbol\": \"last\",\n",
    "        }\n",
    "    )\n",
    "    return new_df\n",
    "\n",
    "def process_bid_ask_data(df, full_symbol, resampling_rule):\n",
    "    # Convert the data to the right format.\n",
    "    converted_df = clean_up_raw_bid_ask_data(df, full_symbol)\n",
    "    # Resample.\n",
    "    converted_resampled_df = resample_bid_ask(converted_df, resampling_rule)\n",
    "    # Convert to multiindex.\n",
    "    converted_resampled_df = dtfsysonod._convert_to_multiindex(\n",
    "        converted_resampled_df, \"full_symbol\"\n",
    "    )\n",
    "    return converted_resampled_df\n",
    "\n",
    "\n",
    "def calculate_bid_ask_statistics(df):\n",
    "    # Configure the node to calculate the returns.\n",
    "    node_bid_ask_config = {\n",
    "        \"in_col_groups\": [\n",
    "            (\"ask_price\",),\n",
    "            (\"ask_size\",),\n",
    "            (\"bid_price\",),\n",
    "            (\"bid_size\",),\n",
    "        ],\n",
    "        \"out_col_group\": (),\n",
    "        \"transformer_kwargs\": {\n",
    "            \"bid_col\": \"bid_price\",\n",
    "            \"ask_col\": \"ask_price\",\n",
    "            \"bid_volume_col\": \"bid_size\",\n",
    "            \"ask_volume_col\": \"ask_size\",\n",
    "        },\n",
    "    }\n",
    "    # Create the node that computes bid ask metrics.\n",
    "    nid = \"process_bid_ask\"\n",
    "    node = dtfcore.GroupedColDfToDfTransformer(\n",
    "        nid,\n",
    "        transformer_func=cfibiask.process_bid_ask,\n",
    "        **node_bid_ask_config,\n",
    "    )\n",
    "    # Compute the node on the data.\n",
    "    bid_ask_metrics = node.fit(df)\n",
    "    # Save the result.\n",
    "    bid_ask_metrics = bid_ask_metrics[\"df_out\"]\n",
    "    return bid_ask_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d75eeb9",
   "metadata": {},
   "source": [
    "## Load, process and calculate metrics for raw bid ask data from crypto-chassis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b344d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of all dates in the range.\n",
    "datelist = pd.date_range(\"2022-01-01\", periods=14).tolist()\n",
    "datelist = [str(x.strftime(\"%Y-%m-%d\")) for x in datelist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434577a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These `full_symbols` need to be loaded (to attach it to historical CCXT data).\n",
    "full_symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c0fdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load `binance::BNB_USDT`.\n",
    "bid_ask_bnb = load_bid_ask_data(\"binance\", \"bnb-usdt\", datelist)\n",
    "# Transforming the data. Data is resampled during its transformation.\n",
    "processed_bid_ask_bnb = process_bid_ask_data(\n",
    "    bid_ask_bnb, \"binance::BNB_USDT\", \"5T\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e947ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load `binance::BTC_USDT`.\n",
    "bid_ask_btc = load_bid_ask_data(\"binance\", \"btc-usdt\", datelist)\n",
    "# Transforming the data. Data is resampled during its transformation.\n",
    "processed_bid_ask_btc = process_bid_ask_data(\n",
    "    bid_ask_btc, \"binance::BTC_USDT\", \"5T\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0abcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unite two `full_symbols`.\n",
    "bid_ask_df = pd.concat([processed_bid_ask_bnb, processed_bid_ask_btc], axis=1)\n",
    "# Calculate bid-ask metrics.\n",
    "bid_ask_df = calculate_bid_ask_statistics(bid_ask_df)\n",
    "bid_ask_df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3d7f6e",
   "metadata": {},
   "source": [
    "## Unite VWAP, TWAP, rets statistics with bid-ask stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8633be",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([vwap_twap_rets_df, bid_ask_df], axis=1)\n",
    "final_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c87bd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics visualizations.\n",
    "final_df.swaplevel(axis=1)[\"binance::BNB_USDT\"][[\"quoted_spread\"]].plot()\n",
    "final_df.swaplevel(axis=1)[\"binance::BNB_USDT\"][[\"relative_spread\"]].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cee040",
   "metadata": {},
   "source": [
    "## Compute the distribution of (return - spread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580e2761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the specific `full_symbol`.\n",
    "df_bnb = final_df.swaplevel(axis=1)[\"binance::BNB_USDT\"]\n",
    "df_bnb.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f5f10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate (|returns| - spread) and display descriptive stats.\n",
    "df_bnb[\"ret_spr_diff\"] = abs(df_bnb[\"close.ret_0\"]) - df_bnb[\"quoted_spread\"]\n",
    "display(df_bnb[\"ret_spr_diff\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b871cd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the result\n",
    "cplonorm.plot_qq(df_bnb[\"ret_spr_diff\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
